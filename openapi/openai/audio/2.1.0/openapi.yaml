openapi: 3.0.0
info:
  title: OpenAI API
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  termsOfService: https://openai.com/policies/terms-of-use
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  version: 2.1.0
servers:
- url: https://api.openai.com/v1
security:
- ApiKeyAuth: []
tags:
- name: Assistants
  description: Build Assistants that can call models and use tools.
- name: Audio
  description: Turn audio into text or text into audio.
- name: Chat
  description: "Given a list of messages comprising a conversation, the model will\
    \ return a response."
- name: Completions
  description: "Given a prompt, the model will return one or more predicted completions,\
    \ and can also return the probabilities of alternative tokens at each position."
- name: Embeddings
  description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
- name: Fine-tuning
  description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
- name: Batch
  description: Create large batches of API requests to run asynchronously.
- name: Files
  description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
- name: Uploads
  description: Use Uploads to upload large files in multiple parts.
- name: Images
  description: "Given a prompt and/or an input image, the model will generate a new\
    \ image."
- name: Models
  description: List and describe the various models available in the API.
- name: Moderations
  description: "Given a input text, outputs if the model classifies it as potentially\
    \ harmful."
paths:
  /chat/completions:
    post:
      tags:
      - Chat
      summary: Creates a model response for the given chat conversation.
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "system", content: "You are a helpful assistant." }],
                  model: "VAR_model_id",
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-4o-mini",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nHello there, how may I assist you today?",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
              }
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4-turbo",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What'\''s in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4-turbo",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4-turbo",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url:
                            "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                        },
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-4o-mini",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_model_id",
                  messages: [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4-turbo",
                "messages": [
                  {
                    "role": "user",
                    "content": "What'\''s the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4-turbo",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99
              }
            }
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-4o-mini",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18
              },
              "system_fingerprint": null
            }
  /completions:
    post:
      tags:
      - Completions
      summary: Creates a completion for the provided prompt and parameters.
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
      x-oaiMeta:
        name: Create completion
        group: completions
        returns: |
          Returns a [completion](/docs/api-reference/completions/object) object, or a sequence of completion objects if the request is streamed.
        legacy: true
        examples:
        - title: No streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.completions.create(
                model="VAR_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.completions.create({
                  model: "VAR_model_id",
                  prompt: "Say this is a test.",
                  max_tokens: 7,
                  temperature: 0,
                });

                console.log(completion);
              }
              main();
          response: |
            {
              "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
              "object": "text_completion",
              "created": 1589478378,
              "model": "VAR_model_id",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [
                {
                  "text": "\n\nThis is indeed a test",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": "length"
                }
              ],
              "usage": {
                "prompt_tokens": 5,
                "completion_tokens": 7,
                "total_tokens": 12
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "prompt": "Say this is a test",
                  "max_tokens": 7,
                  "temperature": 0,
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              for chunk in client.completions.create(
                model="VAR_model_id",
                prompt="Say this is a test",
                max_tokens=7,
                temperature=0,
                stream=True
              ):
                print(chunk.choices[0].text)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.completions.create({
                  model: "VAR_model_id",
                  prompt: "Say this is a test.",
                  stream: true,
                });

                for await (const chunk of stream) {
                  console.log(chunk.choices[0].text)
                }
              }
              main();
          response: |
            {
              "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
              "object": "text_completion",
              "created": 1690759702,
              "choices": [
                {
                  "text": "This",
                  "index": 0,
                  "logprobs": null,
                  "finish_reason": null
                }
              ],
              "model": "gpt-3.5-turbo-instruct"
              "system_fingerprint": "fp_44709d6fcb",
            }
  /images/generations:
    post:
      tags:
      - Images
      summary: Creates an image given a prompt.
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/generations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "dall-e-3",
                  "prompt": "A cute baby sea otter",
                  "n": 1,
                  "size": "1024x1024"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.generate(
                model="dall-e-3",
                prompt="A cute baby sea otter",
                n=1,
                size="1024x1024"
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.generate({ model: "dall-e-3", prompt: "A cute baby sea otter" });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
  /images/edits:
    post:
      tags:
      - Images
      summary: Creates an edited or extended image given an original image and a prompt.
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image edit
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/edits \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F mask="@mask.png" \
                -F prompt="A cute baby sea otter wearing a beret" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.edit(
                image=open("otter.png", "rb"),
                mask=open("mask.png", "rb"),
                prompt="A cute baby sea otter wearing a beret",
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.edit({
                  image: fs.createReadStream("otter.png"),
                  mask: fs.createReadStream("mask.png"),
                  prompt: "A cute baby sea otter wearing a beret",
                });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
  /images/variations:
    post:
      tags:
      - Images
      summary: Creates a variation of a given image.
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
      x-oaiMeta:
        name: Create image variation
        group: images
        returns: "Returns a list of [image](/docs/api-reference/images/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/variations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F n=2 \
                -F size="1024x1024"
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.images.create_variation(
                image=open("image_edit_original.png", "rb"),
                n=2,
                size="1024x1024"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.createVariation({
                  image: fs.createReadStream("otter.png"),
                });

                console.log(image.data);
              }
              main();
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
  /embeddings:
    post:
      tags:
      - Embeddings
      summary: Creates an embedding vector representing the input text.
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: "A list of [embedding](/docs/api-reference/embeddings/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
  /audio/speech:
    post:
      tags:
      - Audio
      summary: Generates audio from the input text.
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        "200":
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              style: simple
              explode: false
              schema:
                type: string
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
      x-oaiMeta:
        name: Create speech
        group: audio
        returns: The audio file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "tts-1",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy"
                }' \
                --output speech.mp3
            python: |
              from pathlib import Path
              import openai

              speech_file_path = Path(__file__).parent / "speech.mp3"
              response = openai.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input="The quick brown fox jumped over the lazy dog."
              )
              response.stream_to_file(speech_file_path)
            node: |
              import fs from "fs";
              import path from "path";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const speechFile = path.resolve("./speech.mp3");

              async function main() {
                const mp3 = await openai.audio.speech.create({
                  model: "tts-1",
                  voice: "alloy",
                  input: "Today is a wonderful day to build something people love!",
                });
                console.log(speechFile);
                const buffer = Buffer.from(await mp3.arrayBuffer());
                await fs.promises.writeFile(speechFile, buffer);
              }
              main();
  /audio/transcriptions:
    post:
      tags:
      - Audio
      summary: Transcribes audio into the input language.
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranscriptionResponse'
      x-oaiMeta:
        name: Create transcription
        group: audio
        returns: "The [transcription object](/docs/api-reference/audio/json-object)\
          \ or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object)."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
              )
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
            }
        - title: Word timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=word" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["word"]
              )

              print(transcript.words)
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["word"]
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "words": [
                {
                  "word": "The",
                  "start": 0.0,
                  "end": 0.23999999463558197
                },
                ...
                {
                  "word": "volleyball",
                  "start": 7.400000095367432,
                  "end": 7.900000095367432
                }
              ]
            }
        - title: Segment timestamps
          request:
            curl: |
              curl https://api.openai.com/v1/audio/transcriptions \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/audio.mp3" \
                -F "timestamp_granularities[]=segment" \
                -F model="whisper-1" \
                -F response_format="verbose_json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.transcriptions.create(
                file=audio_file,
                model="whisper-1",
                response_format="verbose_json",
                timestamp_granularities=["segment"]
              )

              print(transcript.words)
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const transcription = await openai.audio.transcriptions.create({
                  file: fs.createReadStream("audio.mp3"),
                  model: "whisper-1",
                  response_format: "verbose_json",
                  timestamp_granularities: ["segment"]
                });

                console.log(transcription.text);
              }
              main();
          response: |
            {
              "task": "transcribe",
              "language": "english",
              "duration": 8.470000267028809,
              "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
              "segments": [
                {
                  "id": 0,
                  "seek": 0,
                  "start": 0.0,
                  "end": 3.319999933242798,
                  "text": " The beach was a popular spot on a hot summer day.",
                  "tokens": [
                    50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                  ],
                  "temperature": 0.0,
                  "avg_logprob": -0.2860786020755768,
                  "compression_ratio": 1.2363636493682861,
                  "no_speech_prob": 0.00985979475080967
                },
                ...
              ]
            }
  /audio/translations:
    post:
      tags:
      - Audio
      summary: Translates audio into English.
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateTranslationResponse'
      x-oaiMeta:
        name: Create translation
        group: audio
        returns: The translated text.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/translations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/german.m4a" \
                -F model="whisper-1"
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.translations.create(
                model="whisper-1",
                file=audio_file
              )
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                  const translation = await openai.audio.translations.create({
                      file: fs.createReadStream("speech.mp3"),
                      model: "whisper-1",
                  });

                  console.log(translation.text);
              }
              main();
          response: |
            {
              "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
            }
  /files:
    get:
      tags:
      - Files
      summary: Returns a list of files that belong to the user's organization.
      operationId: listFiles
      parameters:
      - name: purpose
        in: query
        description: Only return files with the given purpose
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
      x-oaiMeta:
        name: List files
        group: files
        returns: "A list of [File](/docs/api-reference/files/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.files.list();

                for await (const file of list) {
                  console.log(file);
                }
              }

              main();
          response: |
            {
              "data": [
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 175,
                  "created_at": 1613677385,
                  "filename": "salesOverview.pdf",
                  "purpose": "assistants",
                },
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 140,
                  "created_at": 1613779121,
                  "filename": "puppy.jsonl",
                  "purpose": "fine-tune",
                }
              ],
              "object": "list"
            }
    post:
      tags:
      - Files
      summary: |
        Upload a file that can be used across various endpoints. Individual files can be up to 512 MB, and the size of all files uploaded by one organization can be up to 100 GB.

        The Assistants API supports files up to 2 million tokens and of specific file types. See the [Assistants Tools guide](/docs/assistants/tools) for details.

        The Fine-tuning API only supports `.jsonl` files. The input also has certain required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) models.

        The Batch API only supports `.jsonl` files up to 100 MB in size. The input also has a specific required [format](/docs/api-reference/batch/request-input).

        Please [contact us](https://help.openai.com/) if you need to increase these storage limits.
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Upload file
        group: files
        returns: "The uploaded [File](/docs/api-reference/files/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F purpose="fine-tune" \
                -F file="@mydata.jsonl"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.create(
                file=open("mydata.jsonl", "rb"),
                purpose="fine-tune"
              )
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.create({
                  file: fs.createReadStream("mydata.jsonl"),
                  purpose: "fine-tune",
                });

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
  /files/{fileId}:
    get:
      tags:
      - Files
      summary: Returns information about a specific file.
      operationId: retrieveFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
      x-oaiMeta:
        name: Retrieve file
        group: files
        returns: "The [File](/docs/api-reference/files/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.retrieve("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.retrieve("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
    delete:
      tags:
      - Files
      summary: Delete a file.
      operationId: deleteFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
      x-oaiMeta:
        name: Delete file
        group: files
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.delete("file-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.del("file-abc123");

                console.log(file);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "deleted": true
            }
  /files/{fileId}/content:
    get:
      tags:
      - Files
      summary: Returns the contents of the specified file.
      operationId: downloadFile
      parameters:
      - name: fileId
        in: path
        description: The ID of the file to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                type: string
      x-oaiMeta:
        name: Retrieve file content
        group: files
        returns: The file content.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123/content \
                -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
            python: |
              from openai import OpenAI
              client = OpenAI()

              content = client.files.content("file-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.content("file-abc123");

                console.log(file);
              }

              main();
  /uploads:
    post:
      tags:
      - Uploads
      summary: |
        Creates an intermediate [Upload](/docs/api-reference/uploads/object) object that you can add [Parts](/docs/api-reference/uploads/part-object) to. Currently, an Upload can accept at most 8 GB in total and expires after an hour after you create it.

        Once you complete the Upload, we will create a [File](/docs/api-reference/files/object) object that contains all the parts you uploaded. This File is usable in the rest of our platform as a regular File object.

        For certain `purpose`s, the correct `mime_type` must be specified. Please refer to documentation for the supported MIME types for your use case:
        - [Assistants](/docs/assistants/tools/file-search/supported-files)

        For guidance on the proper filename extensions for each purpose, please follow the documentation on [creating a File](/docs/api-reference/files/create).
      operationId: createUpload
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateUploadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Create upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `pending`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "purpose": "fine-tune",
                  "filename": "training_examples.jsonl",
                  "bytes": 2147483648,
                  "mime_type": "text/jsonl"
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "pending",
              "expires_at": 1719127296
            }
  /uploads/{uploadId}/parts:
    post:
      tags:
      - Uploads
      summary: "Adds a [Part](/docs/api-reference/uploads/part-object) to an [Upload](/docs/api-reference/uploads/object)\
        \ object. A Part represents a chunk of bytes from the file you are trying\
        \ to upload. \n\nEach Part can be at most 64 MB, and you can add Parts until\
        \ you hit the Upload maximum of 8 GB.\n\nIt is possible to add multiple Parts\
        \ in parallel. You can decide the intended order of the Parts when you [complete\
        \ the Upload](/docs/api-reference/uploads/complete).\n"
      operationId: addUploadPart
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AddUploadPartRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/UploadPart'
      x-oaiMeta:
        name: Add upload part
        group: uploads
        returns: "The upload [Part](/docs/api-reference/uploads/part-object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/parts
                -F data="aHR0cHM6Ly9hcGkub3BlbmFpLmNvbS92MS91cGxvYWRz..."
          response: |
            {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719185911,
              "upload_id": "upload_abc123"
            }
  /uploads/{uploadId}/complete:
    post:
      tags:
      - Uploads
      summary: "Completes the [Upload](/docs/api-reference/uploads/object). \n\nWithin\
        \ the returned Upload object, there is a nested [File](/docs/api-reference/files/object)\
        \ object that is ready to use in the rest of the platform.\n\nYou can specify\
        \ the order of the Parts by passing in an ordered list of the Part IDs.\n\n\
        The number of bytes uploaded upon completion must match the number of bytes\
        \ initially specified when creating the Upload object. No Parts may be added\
        \ after an Upload is completed.\n"
      operationId: completeUpload
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompleteUploadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Complete upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `completed` with an additional `file` property containing the created\
          \ usable File object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/complete
                -d '{
                  "part_ids": ["part_def456", "part_ghi789"]
                }'
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "completed",
              "expires_at": 1719127296,
              "file": {
                "id": "file-xyz321",
                "object": "file",
                "bytes": 2147483648,
                "created_at": 1719186911,
                "filename": "training_examples.jsonl",
                "purpose": "fine-tune",
              }
            }
  /uploads/{uploadId}/cancel:
    post:
      tags:
      - Uploads
      summary: |
        Cancels the Upload. No Parts may be added after an Upload is cancelled.
      operationId: cancelUpload
      parameters:
      - name: uploadId
        in: path
        description: |
          The ID of the Upload
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: upload_abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Upload'
      x-oaiMeta:
        name: Cancel upload
        group: uploads
        returns: "The [Upload](/docs/api-reference/uploads/object) object with status\
          \ `cancelled`."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/uploads/upload_abc123/cancel
          response: |
            {
              "id": "upload_abc123",
              "object": "upload",
              "bytes": 2147483648,
              "created_at": 1719184911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
              "status": "cancelled",
              "expires_at": 1719127296
            }
  /fine_tuning/jobs:
    get:
      tags:
      - Fine-tuning
      summary: |
        List your organization's fine-tuning jobs
      operationId: listPaginatedFineTuningJobs
      parameters:
      - name: after
        in: query
        description: Identifier for the last job from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of fine-tuning jobs to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
      x-oaiMeta:
        name: List fine-tuning jobs
        group: fine-tuning
        returns: "A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.jobs.list();

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",
                  "created_at": 1689813489,
                  "level": "warn",
                  "message": "Fine tuning process stopping due to job cancellation",
                  "data": null,
                  "type": "message"
                },
                { ... },
                { ... }
              ], "has_more": true
            }
    post:
      tags:
      - Fine-tuning
      summary: |
        Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

        Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Create fine-tuning job
        group: fine-tuning
        returns: "A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
                  "model": "gpt-3.5-turbo"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-3.5-turbo"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1614807352,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
            }
        - title: Epochs
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "model": "gpt-3.5-turbo",
                  "hyperparameters": {
                    "n_epochs": 2
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                model="gpt-3.5-turbo",
                hyperparameters={
                  "n_epochs":2
                }
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  model: "gpt-3.5-turbo",
                  hyperparameters: { n_epochs: 2 }
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1614807352,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {"n_epochs": 2},
            }
        - title: Validation file
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-3.5-turbo"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.create(
                training_file="file-abc123",
                validation_file="file-def456",
                model="gpt-3.5-turbo"
              )
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.create({
                  training_file: "file-abc123",
                  validation_file: "file-abc123"
                });

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1614807352,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
            }
        - title: W&B Integration
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "training_file": "file-abc123",
                  "validation_file": "file-abc123",
                  "model": "gpt-3.5-turbo",
                  "integrations": [
                    {
                      "type": "wandb",
                      "wandb": {
                        "project": "my-wandb-project",
                        "name": "ft-run-display-name"
                        "tags": [
                          "first-experiment", "v2"
                        ]
                      }
                    }
                  ]
                }'
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1614807352,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "status": "queued",
              "validation_file": "file-abc123",
              "training_file": "file-abc123",
              "integrations": [
                {
                  "type": "wandb",
                  "wandb": {
                    "project": "my-wandb-project",
                    "entity": None,
                    "run_id": "ftjob-abc123"
                  }
                }
              ]
            }
  /fine_tuning/jobs/{fineTuningJobId}:
    get:
      tags:
      - Fine-tuning
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      operationId: retrieveFineTuningJob
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Retrieve fine-tuning job
        group: fine-tuning
        returns: "The [fine-tuning](/docs/api-reference/fine-tuning/object) object\
          \ with the given ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.retrieve("ftjob-abc123")
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");

                console.log(fineTune);
              }

              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "davinci-002",
              "created_at": 1692661014,
              "finished_at": 1692661190,
              "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
              "organization_id": "org-123",
              "result_files": [
                  "file-abc123"
              ],
              "status": "succeeded",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
              },
              "trained_tokens": 5768,
              "integrations": [],
              "seed": 0,
              "estimated_finish": 0
            }
  /fine_tuning/jobs/{fineTuningJobId}/events:
    get:
      tags:
      - Fine-tuning
      summary: |
        Get status updates for a fine-tuning job.
      operationId: listFineTuningEvents
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to get events for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      - name: after
        in: query
        description: Identifier for the last event from the previous pagination request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of events to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
      x-oaiMeta:
        name: List fine-tuning events
        group: fine-tuning
        returns: A list of fine-tuning event objects.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list_events(
                fine_tuning_job_id="ftjob-abc123",
                limit=2
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
                  "created_at": 1692407401,
                  "level": "info",
                  "message": "Fine tuning job successfully completed",
                  "data": null,
                  "type": "message"
                },
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
                  "created_at": 1692407400,
                  "level": "info",
                  "message": "New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel",
                  "data": null,
                  "type": "message"
                }
              ],
              "has_more": true
            }
  /fine_tuning/jobs/{fineTuningJobId}/cancel:
    post:
      tags:
      - Fine-tuning
      summary: |
        Immediately cancel a fine-tune job.
      operationId: cancelFineTuningJob
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
      x-oaiMeta:
        name: Cancel fine-tuning
        group: fine-tuning
        returns: "The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)\
          \ object."
        examples:
          request:
            curl: |
              curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.cancel("ftjob-abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");

                console.log(fineTune);
              }
              main();
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1689376978,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "hyperparameters": {
                "n_epochs":  "auto"
              },
              "status": "cancelled",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
  /fine_tuning/jobs/{fineTuningJobId}/checkpoints:
    get:
      tags:
      - Fine-tuning
      summary: |
        List checkpoints for a fine-tuning job.
      operationId: listFineTuningJobCheckpoints
      parameters:
      - name: fineTuningJobId
        in: path
        description: |
          The ID of the fine-tuning job to get checkpoints for
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
      - name: after
        in: query
        description: Identifier for the last checkpoint ID from the previous pagination
          request
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: Number of checkpoints to retrieve
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 10
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
      x-oaiMeta:
        name: List fine-tuning checkpoints
        group: fine-tuning
        returns: "A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object)\
          \ for a fine-tuning job."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list"
              "data": [
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1519129973,
                  "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom-suffix:96olL566:ckpt-step-2000",
                  "metrics": {
                    "full_valid_loss": 0.134,
                    "full_valid_mean_token_accuracy": 0.874
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 2000,
                },
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1519129833,
                  "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
                  "metrics": {
                    "full_valid_loss": 0.167,
                    "full_valid_mean_token_accuracy": 0.781
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 1000,
                },
              ],
              "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": true
            }
  /models:
    get:
      tags:
      - Models
      summary: "Lists the currently available models, and provides basic information\
        \ about each one such as the owner and availability."
      operationId: listModels
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
      x-oaiMeta:
        name: List models
        group: models
        returns: "A list of [model](/docs/api-reference/models/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.list()
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.models.list();

                for await (const model of list) {
                  console.log(model);
                }
              }
              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "model-id-0",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner"
                },
                {
                  "id": "model-id-1",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner",
                },
                {
                  "id": "model-id-2",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "openai"
                },
              ],
              "object": "list"
            }
  /models/{model}:
    get:
      tags:
      - Models
      summary: "Retrieves a model instance, providing basic information about the\
        \ model such as the owner and permissioning."
      operationId: retrieveModel
      parameters:
      - name: model
        in: path
        description: The ID of the model to use for this request
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: gpt-3.5-turbo
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
      x-oaiMeta:
        name: Retrieve model
        group: models
        returns: "The [model](/docs/api-reference/models/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/VAR_model_id \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.retrieve("VAR_model_id")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.retrieve("VAR_model_id");

                console.log(model);
              }

              main();
          response: |
            {
              "id": "VAR_model_id",
              "object": "model",
              "created": 1686935002,
              "owned_by": "openai"
            }
    delete:
      tags:
      - Models
      summary: Delete a fine-tuned model. You must have the Owner role in your organization
        to delete a model.
      operationId: deleteModel
      parameters:
      - name: model
        in: path
        description: The model to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: ft:gpt-3.5-turbo:acemeco:suffix:abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
      x-oaiMeta:
        name: Delete a fine-tuned model
        group: models
        returns: Deletion status.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/ft:gpt-3.5-turbo:acemeco:suffix:abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.delete("ft:gpt-3.5-turbo:acemeco:suffix:abc123")
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.del("ft:gpt-3.5-turbo:acemeco:suffix:abc123");

                console.log(model);
              }
              main();
          response: |
            {
              "id": "ft:gpt-3.5-turbo:acemeco:suffix:abc123",
              "object": "model",
              "deleted": true
            }
  /moderations:
    post:
      tags:
      - Moderations
      summary: Classifies if text is potentially harmful.
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
      x-oaiMeta:
        name: Create moderation
        group: moderations
        returns: "A [moderation](/docs/api-reference/moderations/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "input": "I want to kill them."
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              moderation = client.moderations.create(input="I want to kill them.")
              print(moderation)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const moderation = await openai.moderations.create({ input: "I want to kill them." });

                console.log(moderation);
              }
              main();
          response: |
            {
              "id": "modr-XXXXX",
              "model": "text-moderation-005",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "sexual": false,
                    "hate": false,
                    "harassment": false,
                    "self-harm": false,
                    "sexual/minors": false,
                    "hate/threatening": false,
                    "violence/graphic": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "harassment/threatening": true,
                    "violence": true,
                  },
                  "category_scores": {
                    "sexual": 1.2282071e-06,
                    "hate": 0.010696256,
                    "harassment": 0.29842457,
                    "self-harm": 1.5236925e-08,
                    "sexual/minors": 5.7246268e-08,
                    "hate/threatening": 0.0060676364,
                    "violence/graphic": 4.435014e-06,
                    "self-harm/intent": 8.098441e-10,
                    "self-harm/instructions": 2.8498655e-11,
                    "harassment/threatening": 0.63055265,
                    "violence": 0.99011886,
                  }
                }
              ]
            }
  /assistants:
    get:
      tags:
      - Assistants
      summary: Returns a list of assistants.
      operationId: listAssistants
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
      x-oaiMeta:
        name: List assistants
        group: assistants
        beta: true
        returns: "A list of [assistant](/docs/api-reference/assistants/object) objects."
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistants = client.beta.assistants.list(
                  order="desc",
                  limit="20",
              )
              print(my_assistants.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistants = await openai.beta.assistants.list({
                  order: "desc",
                  limit: "20",
                });

                console.log(myAssistants.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "asst_abc123",
                  "object": "assistant",
                  "created_at": 1698982736,
                  "name": "Coding Tutor",
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc456",
                  "object": "assistant",
                  "created_at": 1698982718,
                  "name": "My Assistant",
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc789",
                  "object": "assistant",
                  "created_at": 1698982643,
                  "name": null,
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                }
              ],
              "first_id": "asst_abc123",
              "last_id": "asst_abc789",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create an assistant with a model and instructions.
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Create assistant
        group: assistants
        beta: true
        returns: "An [assistant](/docs/api-reference/assistants/object) object."
        examples:
        - title: Code Interpreter
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  "name": "Math Tutor",
                  "tools": [{"type": "code_interpreter"}],
                  "model": "gpt-4-turbo"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name="Math Tutor",
                  tools=[{"type": "code_interpreter"}],
                  model="gpt-4-turbo",
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                  name: "Math Tutor",
                  tools: [{ type: "code_interpreter" }],
                  model: "gpt-4-turbo",
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1698984975,
              "name": "Math Tutor",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        - title: Files
          request:
            curl: |
              curl https://api.openai.com/v1/assistants \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  "tools": [{"type": "file_search"}],
                  "tool_resources": {"file_search": {"vector_store_ids": ["vs_123"]}},
                  "model": "gpt-4-turbo"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.create(
                  instructions="You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name="HR Helper",
                  tools=[{"type": "file_search"}],
                  tool_resources={"file_search": {"vector_store_ids": ["vs_123"]}},
                  model="gpt-4-turbo"
              )
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.create({
                  instructions:
                    "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                  name: "HR Helper",
                  tools: [{ type: "file_search" }],
                  tool_resources: {
                    file_search: {
                      vector_store_ids: ["vs_123"]
                    }
                  },
                  model: "gpt-4-turbo"
                });

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009403,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
  /assistants/{assistantId}:
    get:
      tags:
      - Assistants
      summary: Retrieves an assistant.
      operationId: getAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Retrieve assistant
        group: assistants
        beta: true
        returns: "The [assistant](/docs/api-reference/assistants/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.retrieve("asst_abc123")
              print(my_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.retrieve(
                  "asst_abc123"
                );

                console.log(myAssistant);
              }

              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
    post:
      tags:
      - Assistants
      summary: Modifies an assistant.
      operationId: modifyAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
      x-oaiMeta:
        name: Modify assistant
        group: assistants
        beta: true
        returns: "The modified [assistant](/docs/api-reference/assistants/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    "tools": [{"type": "file_search"}],
                    "model": "gpt-4-turbo"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_assistant = client.beta.assistants.update(
                "asst_abc123",
                instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                name="HR Helper",
                tools=[{"type": "file_search"}],
                model="gpt-4-turbo"
              )

              print(my_updated_assistant)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myUpdatedAssistant = await openai.beta.assistants.update(
                  "asst_abc123",
                  {
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    model: "gpt-4-turbo"
                  }
                );

                console.log(myUpdatedAssistant);
              }

              main();
          response: |
            {
              "id": "asst_123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": []
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
    delete:
      tags:
      - Assistants
      summary: Delete an assistant.
      operationId: deleteAssistant
      parameters:
      - name: assistantId
        in: path
        description: The ID of the assistant to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
      x-oaiMeta:
        name: Delete assistant
        group: assistants
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.assistants.delete("asst_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.assistants.del("asst_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant.deleted",
              "deleted": true
            }
  /threads:
    post:
      tags:
      - Assistants
      summary: Create a thread.
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Create thread
        group: threads
        beta: true
        returns: "A [thread](/docs/api-reference/threads) object."
        examples:
        - title: Empty
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d ''
            python: |
              from openai import OpenAI
              client = OpenAI()

              empty_thread = client.beta.threads.create()
              print(empty_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const emptyThread = await openai.beta.threads.create();

                console.log(emptyThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699012949,
              "metadata": {},
              "tool_resources": {}
            }
        - title: Messages
          request:
            curl: |
              curl https://api.openai.com/v1/threads \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -H "OpenAI-Beta: assistants=v2" \
              -d '{
                  "messages": [{
                    "role": "user",
                    "content": "Hello, what is AI?"
                  }, {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message_thread = client.beta.threads.create(
                messages=[
                  {
                    "role": "user",
                    "content": "Hello, what is AI?"
                  },
                  {
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  },
                ]
              )

              print(message_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messageThread = await openai.beta.threads.create({
                  messages: [
                    {
                      role: "user",
                      content: "Hello, what is AI?"
                    },
                    {
                      role: "user",
                      content: "How does AI work? Explain it in simple terms.",
                    },
                  ],
                });

                console.log(messageThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {}
            }
  /threads/{threadId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a thread.
      operationId: getThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Retrieve thread
        group: threads
        beta: true
        returns: "The [thread](/docs/api-reference/threads/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_thread = client.beta.threads.retrieve("thread_abc123")
              print(my_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myThread = await openai.beta.threads.retrieve(
                  "thread_abc123"
                );

                console.log(myThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
    post:
      tags:
      - Assistants
      summary: Modifies a thread.
      operationId: modifyThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to modify. Only the `metadata` can be modified
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
      x-oaiMeta:
        name: Modify thread
        group: threads
        beta: true
        returns: "The modified [thread](/docs/api-reference/threads/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_thread = client.beta.threads.update(
                "thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123"
                }
              )
              print(my_updated_thread)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const updatedThread = await openai.beta.threads.update(
                  "thread_abc123",
                  {
                    metadata: { modified: "true", user: "abc123" },
                  }
                );

                console.log(updatedThread);
              }

              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
    delete:
      tags:
      - Assistants
      summary: Delete a thread.
      operationId: deleteThread
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
      x-oaiMeta:
        name: Delete thread
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.threads.delete("thread_abc123")
              print(response)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.threads.del("thread_abc123");

                console.log(response);
              }
              main();
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
  /threads/{threadId}/messages:
    get:
      tags:
      - Assistants
      summary: Returns a list of messages for a given thread.
      operationId: listMessages
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) the messages\
          \ belong to"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: run_id
        in: query
        description: |
          Filter messages by the run ID that generated them
        required: false
        style: form
        explode: true
        schema:
          type: string
        x-ballerina-name: runId
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
      x-oaiMeta:
        name: List messages
        group: threads
        beta: true
        returns: "A list of [message](/docs/api-reference/messages) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_messages = client.beta.threads.messages.list("thread_abc123")
              print(thread_messages.data)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.list(
                  "thread_abc123"
                );

                console.log(threadMessages.data);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create a message.
      operationId: createMessage
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to create\
          \ a message for"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Create message
        group: threads
        beta: true
        returns: "A [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_message = client.beta.threads.messages.create(
                "thread_abc123",
                role="user",
                content="How does AI work? Explain it in simple terms.",
              )
              print(thread_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.create(
                  "thread_abc123",
                  { role: "user", content: "How does AI work? Explain it in simple terms." }
                );

                console.log(threadMessages);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
  /threads/{threadId}/messages/{messageId}:
    get:
      tags:
      - Assistants
      summary: Retrieve a message.
      operationId: getMessage
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this message belongs"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Retrieve message
        group: threads
        beta: true
        returns: "The [message](/docs/api-reference/messages/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.retrieve(
                message_id="msg_abc123",
                thread_id="thread_abc123",
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.retrieve(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(message);
              }

              main();
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
    post:
      tags:
      - Assistants
      summary: Modifies a message.
      operationId: modifyMessage
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this message belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
      x-oaiMeta:
        name: Modify message
        group: threads
        beta: true
        returns: "The modified [message](/docs/api-reference/messages/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.update(
                message_id="msg_abc12",
                thread_id="thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123",
                },
              )
              print(message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.update(
                  "thread_abc123",
                  "msg_abc123",
                  {
                    metadata: {
                      modified: "true",
                      user: "abc123",
                    },
                  }
                }'
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
    delete:
      tags:
      - Assistants
      summary: Deletes a message.
      operationId: deleteMessage
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this message belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: messageId
        in: path
        description: The ID of the message to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
      x-oaiMeta:
        name: Delete message
        group: threads
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_message = client.beta.threads.messages.delete(
                message_id="msg_abc12",
                thread_id="thread_abc123",
              )
              print(deleted_message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const deletedMessage = await openai.beta.threads.messages.del(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(deletedMessage);
              }
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
  /threads/runs:
    post:
      tags:
      - Assistants
      summary: Create a thread and run it in one request.
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create thread and run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Explain deep learning to a 5 year old."}
                      ]
                    }
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.create_and_run(
                assistant_id="asst_abc123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Explain deep learning to a 5 year old."}
                  ]
                }
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_abc123",
                  thread: {
                    messages: [
                      { role: "user", content: "Explain deep learning to a 5 year old." },
                    ],
                  },
                });

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076792,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": null,
              "expires_at": 1699077392,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "required_action": null,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": "You are a helpful assistant.",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "temperature": 1.0,
              "top_p": 1.0,
              "max_completion_tokens": null,
              "max_prompt_tokens": null,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "incomplete_details": null,
              "usage": null,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "Hello"}
                    ]
                  },
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.create_and_run(
                assistant_id="asst_123",
                thread={
                  "messages": [
                    {"role": "user", "content": "Hello"}
                  ]
                },
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_123",
                    thread: {
                      messages: [
                        { role: "user", content: "Hello" },
                      ],
                    },
                    stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[], "metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}], "metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "thread": {
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                  },
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.create_and_run(
                thread={
                    "messages": [
                      {"role": "user", "content": "What is the weather like in San Francisco?"}
                    ]
                },
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.createAndRun({
                  assistant_id: "asst_123",
                  thread: {
                    messages: [
                      { role: "user", content: "What is the weather like in San Francisco?" },
                    ],
                  },
                  tools: tools,
                  stream: true
                });

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.created
            data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}

            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}

            ...

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}

            event: thread.run.step.delta
            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}

            event: thread.run.requires_action
            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{threadId}/runs:
    get:
      tags:
      - Assistants
      summary: Returns a list of runs belonging to a thread.
      operationId: listRuns
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread the run belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
      x-oaiMeta:
        name: List runs
        group: threads
        beta: true
        returns: "A list of [run](/docs/api-reference/runs/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.beta.threads.runs.list(
                "thread_abc123"
              )

              print(runs)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const runs = await openai.beta.threads.runs.list(
                  "thread_abc123"
                );

                console.log(runs);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto",
                  "parallel_tool_calls": true
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
    post:
      tags:
      - Assistants
      summary: Create a run.
      operationId: createRun
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to run
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Create run
        group: threads
        beta: true
        returns: "A [run](/docs/api-reference/runs/object) object."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  { assistant_id: "asst_abc123" }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699063290,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "queued",
              "started_at": 1699063290,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699063291,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_123",
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.create(
                thread_id="thread_123",
                assistant_id="asst_123",
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_123",
                  { assistant_id: "asst_123", stream: true }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
        - title: Streaming with Functions
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "assistant_id": "asst_abc123",
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]

              stream = client.beta.threads.runs.create(
                thread_id="thread_abc123",
                assistant_id="asst_abc123",
                tools=tools,
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              const tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
              ];

              async function main() {
                const stream = await openai.beta.threads.runs.create(
                  "thread_abc123",
                  {
                    assistant_id: "asst_abc123",
                    tools: tools,
                    stream: true
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.created
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" today"}}]}}

            event: thread.message.delta
            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}

            event: thread.message.completed
            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello! How can I assist you today?","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{threadId}/runs/{runId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a run.
      operationId: getRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Retrieve run
        group: threads
        beta: true
        returns: "The [run](/docs/api-reference/runs/object) object matching the specified\
          \ ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.retrieve(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.retrieve(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
    post:
      tags:
      - Assistants
      summary: Modifies a run.
      operationId: modifyRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) that was\
          \ run"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Modify run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.update(
                thread_id="thread_abc123",
                run_id="run_abc123",
                metadata={"user_id": "user_abc123"},
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.update(
                  "thread_abc123",
                  "run_abc123",
                  {
                    metadata: {
                      user_id: "user_abc123",
                    },
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{threadId}/runs/{runId}/submit_tool_outputs:
    post:
      tags:
      - Assistants
      summary: |
        When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.
      operationId: submitToolOuputsToRun
      parameters:
      - name: threadId
        in: path
        description: "The ID of the [thread](/docs/api-reference/threads) to which\
          \ this run belongs"
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run that requires the tool output submission
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Submit tool outputs to run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ]
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_123",
              "object": "thread.run",
              "created_at": 1699075592,
              "assistant_id": "asst_123",
              "thread_id": "thread_123",
              "status": "queued",
              "started_at": 1699075592,
              "expires_at": 1699076192,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "tools": [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA"
                        },
                        "unit": {
                          "type": "string",
                          "enum": ["celsius", "fahrenheit"]
                        }
                      },
                      "required": ["location"]
                    }
                  }
                }
              ],
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "tool_outputs": [
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              stream = client.beta.threads.runs.submit_tool_outputs(
                thread_id="thread_123",
                run_id="run_123",
                tool_outputs=[
                  {
                    "tool_call_id": "call_001",
                    "output": "70 degrees and sunny."
                  }
                ],
                stream=True
              )

              for event in stream:
                print(event)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const stream = await openai.beta.threads.runs.submitToolOutputs(
                  "thread_123",
                  "run_123",
                  {
                    tool_outputs: [
                      {
                        tool_call_id: "call_001",
                        output: "70 degrees and sunny.",
                      },
                    ],
                  }
                );

                for await (const event of stream) {
                  console.log(event);
                }
              }

              main();
          response: |
            event: thread.run.step.completed
            data: {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}

            event: thread.run.queued
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.in_progress
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: thread.run.step.created
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.run.step.in_progress
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}

            event: thread.message.created
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.in_progress
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" current"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" weather"}}]}}

            ...

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":" sunny"}}]}}

            event: thread.message.delta
            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}

            event: thread.message.completed
            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.","annotations":[]}}],"metadata":{}}

            event: thread.run.step.completed
            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}

            event: thread.run.completed
            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}

            event: done
            data: [DONE]
  /threads/{threadId}/runs/{runId}/cancel:
    post:
      tags:
      - Assistants
      summary: Cancels a run that is `in_progress`.
      operationId: cancelRun
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which this run belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
      x-oaiMeta:
        name: Cancel a run
        group: threads
        beta: true
        returns: "The modified [run](/docs/api-reference/runs/object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.cancel(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.cancel(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto",
              "tool_choice": "auto",
              "parallel_tool_calls": true
            }
  /threads/{threadId}/runs/{runId}/steps:
    get:
      tags:
      - Assistants
      summary: Returns a list of run steps belonging to a run.
      operationId: listRunSteps
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread the run and run steps belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run the run steps belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
      x-oaiMeta:
        name: List run steps
        group: threads
        beta: true
        returns: "A list of [run step](/docs/api-reference/runs/step-object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_steps = client.beta.threads.runs.steps.list(
                  thread_id="thread_abc123",
                  run_id="run_abc123"
              )

              print(run_steps)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.list(
                  "thread_abc123",
                  "run_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
  /threads/{threadId}/runs/{runId}/steps/{stepId}:
    get:
      tags:
      - Assistants
      summary: Retrieves a run step.
      operationId: getRunStep
      parameters:
      - name: threadId
        in: path
        description: The ID of the thread to which the run and run step belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: runId
        in: path
        description: The ID of the run to which the run step belongs
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: stepId
        in: path
        description: The ID of the run step to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
      x-oaiMeta:
        name: Retrieve run step
        group: threads
        beta: true
        returns: "The [run step](/docs/api-reference/runs/step-object) object matching\
          \ the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_step = client.beta.threads.runs.steps.retrieve(
                  thread_id="thread_abc123",
                  run_id="run_abc123",
                  step_id="step_abc123"
              )

              print(run_step)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.retrieve(
                  "thread_abc123",
                  "run_abc123",
                  "step_abc123"
                );
                console.log(runStep);
              }

              main();
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
  /vector_stores:
    get:
      tags:
      - Vector Stores
      summary: Returns a list of vector stores.
      operationId: listVectorStores
      parameters:
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
      x-oaiMeta:
        name: List vector stores
        group: vector_stores
        beta: true
        returns: "A list of [vector store](/docs/api-reference/vector-stores/object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_stores = client.beta.vector_stores.list()
              print(vector_stores)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStores = await openai.beta.vectorStores.list();
                console.log(vectorStores);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
    post:
      tags:
      - Vector Stores
      summary: Create a vector store.
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Create vector store
        group: vector_stores
        beta: true
        returns: "A [vector store](/docs/api-reference/vector-stores/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.create(
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.create({
                  name: "Support FAQ"
                });
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
  /vector_stores/{vectorStoreId}:
    get:
      tags:
      - Vector Stores
      summary: Retrieves a vector store.
      operationId: getVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Retrieve vector store
        group: vector_stores
        beta: true
        returns: "The [vector store](/docs/api-reference/vector-stores/object) object\
          \ matching the specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.retrieve(
                vector_store_id="vs_abc123"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.retrieve(
                  "vs_abc123"
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
    post:
      tags:
      - Vector Stores
      summary: Modifies a vector store.
      operationId: modifyVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to modify
        required: true
        style: simple
        explode: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
      x-oaiMeta:
        name: Modify vector store
        group: vector_stores
        beta: true
        returns: "The modified [vector store](/docs/api-reference/vector-stores/object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.update(
                vector_store_id="vs_abc123",
                name="Support FAQ"
              )
              print(vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.update(
                  "vs_abc123",
                  {
                    name: "Support FAQ"
                  }
                );
                console.log(vectorStore);
              }

              main();
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
    delete:
      tags:
      - Vector Stores
      summary: Delete a vector store.
      operationId: deleteVectorStore
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
      x-oaiMeta:
        name: Delete vector store
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store = client.beta.vector_stores.delete(
                vector_store_id="vs_abc123"
              )
              print(deleted_vector_store)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStore = await openai.beta.vectorStores.del(
                  "vs_abc123"
                );
                console.log(deletedVectorStore);
              }

              main();
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
  /vector_stores/{vectorStoreId}/files:
    get:
      tags:
      - Vector Stores
      summary: Returns a list of vector store files.
      operationId: listVectorStoreFiles
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: filter
        in: query
        description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files
        group: vector_stores
        beta: true
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.beta.vector_stores.files.list(
                vector_store_id="vs_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.files.list(
                  "vs_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
    post:
      tags:
      - Vector Stores
      summary: "Create a vector store file by attaching a [File](/docs/api-reference/files)\
        \ to a [vector store](/docs/api-reference/vector-stores/object)."
      operationId: createVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: |
          The ID of the vector store for which to create a File
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Create vector store file
        group: vector_stores
        beta: true
        returns: "A [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.create(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFile = await openai.beta.vectorStores.files.create(
                  "vs_abc123",
                  {
                    file_id: "file-abc123"
                  }
                );
                console.log(myVectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
  /vector_stores/{vectorStoreId}/files/{fileId}:
    get:
      tags:
      - Vector Stores
      summary: Retrieves a vector store file.
      operationId: getVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: fileId
        in: path
        description: The ID of the file being retrieved
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: file-abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
      x-oaiMeta:
        name: Retrieve vector store file
        group: vector_stores
        beta: true
        returns: "The [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.retrieve(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFile = await openai.beta.vectorStores.files.retrieve(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(vectorStoreFile);
              }

              main();
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
    delete:
      tags:
      - Vector Stores
      summary: "Delete a vector store file. This will remove the file from the vector\
        \ store but the file itself will not be deleted. To delete the file, use the\
        \ [delete file](/docs/api-reference/files/delete) endpoint."
      operationId: deleteVectorStoreFile
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: fileId
        in: path
        description: The ID of the file to delete
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
      x-oaiMeta:
        name: Delete vector store file
        group: vector_stores
        beta: true
        returns: Deletion status
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file = client.beta.vector_stores.files.delete(
                  vector_store_id="vs_abc123",
                  file_id="file-abc123"
              )
              print(deleted_vector_store_file)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFile = await openai.beta.vectorStores.files.del(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(deletedVectorStoreFile);
              }

              main();
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
  /vector_stores/{vectorStoreId}/file_batches:
    post:
      tags:
      - Vector Stores
      summary: Create a vector store file batch.
      operationId: createVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: |
          The ID of the vector store for which to create a File Batch
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Create vector store file batch
        group: vector_stores
        beta: true
        returns: "A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_ids": ["file-abc123", "file-abc456"]
                  }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.beta.vector_stores.file_batches.create(
                vector_store_id="vs_abc123",
                file_ids=["file-abc123", "file-abc456"]
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.create(
                  "vs_abc123",
                  {
                    file_ids: ["file-abc123", "file-abc456"]
                  }
                );
                console.log(myVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}:
    get:
      tags:
      - Vector Stores
      summary: Retrieves a vector store file batch.
      operationId: getVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file batch belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vs_abc123
      - name: batchId
        in: path
        description: The ID of the file batch being retrieved
        required: true
        style: simple
        explode: false
        schema:
          type: string
          example: vsfb_abc123
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Retrieve vector store file batch
        group: vector_stores
        beta: true
        returns: "The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)\
          \ object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file_batch = client.beta.vector_stores.file_batches.retrieve(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.retrieve(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}/cancel:
    post:
      tags:
      - Vector Stores
      summary: Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      operationId: cancelVectorStoreFileBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the file batch belongs to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: batchId
        in: path
        description: The ID of the file batch to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
      x-oaiMeta:
        name: Cancel vector store file batch
        group: vector_stores
        beta: true
        returns: The modified vector store file batch object.
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store_file_batch = client.beta.vector_stores.file_batches.cancel(
                  vector_store_id="vs_abc123",
                  file_batch_id="vsfb_abc123"
              )
              print(deleted_vector_store_file_batch)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFileBatch = await openai.vector_stores.fileBatches.cancel(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(deletedVectorStoreFileBatch);
              }

              main();
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "cancelling",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
  /vector_stores/{vectorStoreId}/file_batches/{batchId}/files:
    get:
      tags:
      - Vector Stores
      summary: Returns a list of vector store files in a batch.
      operationId: listFilesInVectorStoreBatch
      parameters:
      - name: vectorStoreId
        in: path
        description: The ID of the vector store that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: batchId
        in: path
        description: The ID of the file batch that the files belong to
        required: true
        style: simple
        explode: false
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      - name: order
        in: query
        description: |
          Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
        required: false
        style: form
        explode: true
        schema:
          type: string
          default: desc
          enum:
          - asc
          - desc
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: before
        in: query
        description: |
          A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: filter
        in: query
        description: "Filter by file status. One of `in_progress`, `completed`, `failed`,\
          \ `cancelled`"
        required: false
        style: form
        explode: true
        schema:
          type: string
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
      x-oaiMeta:
        name: List vector store files in a batch
        group: vector_stores
        beta: true
        returns: "A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)\
          \ objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.beta.vector_stores.file_batches.list_files(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )
              print(vector_store_files)
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.fileBatches.listFiles(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
  /batches:
    get:
      tags:
      - Batch
      summary: List your organization's batches.
      operationId: listBatches
      parameters:
      - name: after
        in: query
        description: |
          A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
        required: false
        style: form
        explode: true
        schema:
          type: string
      - name: limit
        in: query
        description: |
          A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
        required: false
        style: form
        explode: true
        schema:
          type: integer
          default: 20
      responses:
        "200":
          description: Batch listed successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
      x-oaiMeta:
        name: List batch
        group: batch
        returns: "A list of paginated [Batch](/docs/api-reference/batch/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.list()
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.batches.list();

                for await (const batch of list) {
                  console.log(batch);
                }
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "batch_abc123",
                  "object": "batch",
                  "endpoint": "/v1/chat/completions",
                  "errors": null,
                  "input_file_id": "file-abc123",
                  "completion_window": "24h",
                  "status": "completed",
                  "output_file_id": "file-cvaTdG",
                  "error_file_id": "file-HOWS94",
                  "created_at": 1711471533,
                  "in_progress_at": 1711471538,
                  "expires_at": 1711557933,
                  "finalizing_at": 1711493133,
                  "completed_at": 1711493163,
                  "failed_at": null,
                  "expired_at": null,
                  "cancelling_at": null,
                  "cancelled_at": null,
                  "request_counts": {
                    "total": 100,
                    "completed": 95,
                    "failed": 5
                  },
                  "metadata": {
                    "customer_id": "user_123456789",
                    "batch_description": "Nightly job",
                  }
                },
                { ... },
              ],
              "first_id": "batch_abc123",
              "last_id": "batch_abc456",
              "has_more": true
            }
    post:
      tags:
      - Batch
      summary: Creates and executes a batch from an uploaded file of requests
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BatchesBody'
        required: true
      responses:
        "200":
          description: Batch created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Create batch
        group: batch
        returns: "The created [Batch](/docs/api-reference/batch/object) object."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input_file_id": "file-abc123",
                  "endpoint": "/v1/chat/completions",
                  "completion_window": "24h"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.create(
                input_file_id="file-abc123",
                endpoint="/v1/chat/completions",
                completion_window="24h"
              )
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.create({
                  input_file_id: "file-abc123",
                  endpoint: "/v1/chat/completions",
                  completion_window: "24h"
                });

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "validating",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": null,
              "expires_at": null,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 0,
                "completed": 0,
                "failed": 0
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batchId}:
    get:
      tags:
      - Batch
      summary: Retrieves a batch.
      operationId: retrieveBatch
      parameters:
      - name: batchId
        in: path
        description: The ID of the batch to retrieve
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Batch retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Retrieve batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.retrieve("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.retrieve("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "completed",
              "output_file_id": "file-cvaTdG",
              "error_file_id": "file-HOWS94",
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": 1711493133,
              "completed_at": 1711493163,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 95,
                "failed": 5
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
  /batches/{batchId}/cancel:
    post:
      tags:
      - Batch
      summary: "Cancels an in-progress batch. The batch will be in status `cancelling`\
        \ for up to 10 minutes, before changing to `cancelled`, where it will have\
        \ partial results (if any) available in the output file."
      operationId: cancelBatch
      parameters:
      - name: batchId
        in: path
        description: The ID of the batch to cancel
        required: true
        style: simple
        explode: false
        schema:
          type: string
      responses:
        "200":
          description: Batch is cancelling. Returns the cancelling batch's details
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
      x-oaiMeta:
        name: Cancel batch
        group: batch
        returns: "The [Batch](/docs/api-reference/batch/object) object matching the\
          \ specified ID."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -X POST
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.cancel("batch_abc123")
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.cancel("batch_abc123");

                console.log(batch);
              }

              main();
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "cancelling",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": 1711475133,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 23,
                "failed": 1
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
components:
  schemas:
    BatchRequestCounts:
      required:
      - completed
      - failed
      - total
      type: object
      properties:
        total:
          type: integer
          description: Total number of requests in the batch
        completed:
          type: integer
          description: Number of requests that have been completed successfully
        failed:
          type: integer
          description: Number of requests that have failed
      description: The request counts for different statuses within the batch
    DoneEvent:
      required:
      - data
      - event
      type: object
      properties:
        data:
          type: string
          enum:
          - "[DONE]"
        event:
          type: string
          enum:
          - done
      description: Occurs when a stream ends
      x-oaiMeta:
        dataDescription: "`data` is `[DONE]`"
    FineTuningJobCheckpoint:
      title: FineTuningJobCheckpoint
      required:
      - created_at
      - fine_tuned_model_checkpoint
      - fine_tuning_job_id
      - id
      - metrics
      - object
      - step_number
      type: object
      properties:
        step_number:
          type: integer
          description: The step number that the checkpoint was created at
          x-ballerina-name: stepNumber
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created
          x-ballerina-name: createdAt
        fine_tuning_job_id:
          type: string
          description: The name of the fine-tuning job that this checkpoint was created
            from
          x-ballerina-name: fineTuningJobId
        id:
          type: string
          description: "The checkpoint identifier, which can be referenced in the\
            \ API endpoints"
        metrics:
          $ref: '#/components/schemas/FineTuningJobCheckpointMetrics'
        fine_tuned_model_checkpoint:
          type: string
          description: The name of the fine-tuned checkpoint model that is created
          x-ballerina-name: fineTunedModelCheckpoint
        object:
          type: string
          description: "The object type, which is always \"fine_tuning.job.checkpoint\""
          enum:
          - fine_tuning.job.checkpoint
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: |
          {
            "object": "fine_tuning.job.checkpoint",
            "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
            "created_at": 1712211699,
            "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
            "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
            "metrics": {
              "step": 88,
              "train_loss": 0.478,
              "train_mean_token_accuracy": 0.924,
              "valid_loss": 10.112,
              "valid_mean_token_accuracy": 0.145,
              "full_valid_loss": 0.567,
              "full_valid_mean_token_accuracy": 0.944
            },
            "step_number": 88
          }
    MessageDeltaContentTextObjectText:
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/MessageDeltaContentTextObjectTextAnnotations'
        value:
          type: string
          description: The data that makes up the text
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
      - file_search
      - index
      - type
      type: object
      properties:
        file_search:
          type: object
          description: "For now, this is always going to be an empty object"
          x-oaiTypeLabel: map
          x-ballerina-name: fileSearch
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call
          enum:
          - file_search
    AssistantsApiToolChoiceOptionOneOf1:
      type: string
      description: |
        `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user
      enum:
      - none
      - auto
      - required
    ListRunsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: run_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunObject'
        last_id:
          type: string
          example: run_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
    AssistantsApiResponseFormatOption:
      description: |
        Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models/gpt-4o), [GPT-4 Turbo](/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length
      oneOf:
      - $ref: '#/components/schemas/AssistantsApiResponseFormatOptionOneOf1'
      - $ref: '#/components/schemas/AssistantsApiResponseFormat'
      x-oaiExpandable: true
    RunStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObjectFunction'
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `function`
            for this type of tool call
          enum:
          - function
    CreateRunRequest:
      required:
      - assistant_id
      - thread_id
      type: object
      properties:
        instructions:
          type: string
          description: "Overrides the [instructions](/docs/api-reference/assistants/createAssistant)\
            \ of the assistant. This is useful for modifying the behavior on a per-run\
            \ basis"
          nullable: true
        additional_instructions:
          type: string
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions
          nullable: true
          x-ballerina-name: additionalInstructions
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run"
          x-ballerina-name: assistantId
        additional_messages:
          type: array
          description: Adds additional messages to the thread before creating the
            run
          nullable: true
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          x-ballerina-name: additionalMessages
        tools:
          maxItems: 20
          type: array
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
          items:
            $ref: '#/components/schemas/CreateRunRequestTools'
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          x-ballerina-name: truncationStrategy
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxCompletionTokens
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          x-ballerina-name: toolChoice
        model:
          description: "The ID of the [Model](/docs/api-reference/models) to be used\
            \ to execute this run. If a value is provided here, it will override the\
            \ model associated with the assistant. If not, the model associated with\
            \ the assistant will be used"
          nullable: true
          example: gpt-4-turbo
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4o-mini
            - gpt-4o-mini-2024-07-18
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
          x-oaiTypeLabel: string
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxPromptTokens
      additionalProperties: false
    ListFineTuningJobCheckpointsResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          nullable: true
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
        last_id:
          type: string
          nullable: true
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionToolChoiceOptionOneOf1'
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
      x-oaiExpandable: true
    RunObjectRequiredAction:
      required:
      - submit_tool_outputs
      - type
      type: object
      properties:
        submit_tool_outputs:
          allOf:
          - $ref: '#/components/schemas/RunObjectRequiredActionSubmitToolOutputs'
          x-ballerina-name: submitToolOutputs
        type:
          type: string
          description: "For now, this is always `submit_tool_outputs`"
          enum:
          - submit_tool_outputs
      description: Details on the action required to continue the run. Will be `null`
        if no action is required
      nullable: true
    AutoChunkingStrategyRequestParam:
      title: Auto Chunking Strategy
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `auto`
          enum:
          - auto
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`
    AssistantToolsFileSearchTypeOnly:
      title: FileSearch tool
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
    AssistantToolsFileSearch:
      title: FileSearch tool
      required:
      - type
      type: object
      properties:
        file_search:
          allOf:
          - $ref: '#/components/schemas/AssistantToolsFileSearchFileSearch'
          x-ballerina-name: fileSearch
        type:
          type: string
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
    CreateMessageRequestAttachments:
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file to attach to the message
          x-ballerina-name: fileId
        tools:
          type: array
          description: The tools to add this file to
          items:
            $ref: '#/components/schemas/CreateMessageRequestTools'
    ChatCompletionMessageToolCalls:
      type: array
      description: "The tool calls generated by the model, such as function calls"
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
    MessageDeltaObjectDeltaContent:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextObject'
      - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
      x-oaiExpandable: true
    CreateEmbeddingRequest:
      required:
      - input
      - model
      type: object
      properties:
        input:
          description: |
            Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
          example: The quick brown fox jumped over the lazy dog
          oneOf:
          - title: string
            type: string
            description: The string that will be turned into an embedding.
            example: This is a test.
            default: ""
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of strings that will be turned into an embedding.
            items:
              type: string
              example: "['This is a test.']"
              default: ""
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of integers that will be turned into an embedding.
            example: "[1212, 318, 257, 1332, 13]"
            items:
              type: integer
          - title: array
            maxItems: 2048
            minItems: 1
            type: array
            description: The array of arrays containing integers that will be turned
              into an embedding.
            example: "[[1212, 318, 257, 1332, 13]]"
            items:
              minItems: 1
              type: array
              items:
                type: integer
          x-oaiExpandable: true
        encoding_format:
          type: string
          description: "The format to return the embeddings in. Can be either `float`\
            \ or [`base64`](https://pypi.org/project/pybase64/)"
          example: float
          default: float
          enum:
          - float
          - base64
          x-ballerina-name: encodingFormat
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
          example: text-embedding-3-small
          anyOf:
          - type: string
          - type: string
            enum:
            - text-embedding-ada-002
            - text-embedding-3-small
            - text-embedding-3-large
          x-oaiTypeLabel: string
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
        dimensions:
          minimum: 1
          type: integer
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models
      additionalProperties: false
    ChatCompletionTokenLogprobTopLogprobs:
      required:
      - bytes
      - logprob
      - token
      type: object
      properties:
        logprob:
          type: number
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely"
        bytes:
          type: array
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token
          nullable: true
          items:
            type: integer
        token:
          type: string
          description: The token
    ParallelToolCalls:
      type: boolean
      description: "Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)\
        \ during tool use"
      default: true
    CreateModerationRequest:
      required:
      - input
      type: object
      properties:
        input:
          description: The input text to classify
          oneOf:
          - type: string
            example: I want to kill them.
            default: ""
          - type: array
            items:
              type: string
              example: I want to kill them.
              default: ""
        model:
          description: |
            Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.

            The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`
          nullable: false
          example: text-moderation-stable
          anyOf:
          - type: string
          - type: string
            enum:
            - text-moderation-latest
            - text-moderation-stable
          default: text-moderation-latest
          x-oaiTypeLabel: string
    CreateUploadRequest:
      required:
      - bytes
      - filename
      - mime_type
      - purpose
      type: object
      properties:
        filename:
          type: string
          description: |
            The name of the file to upload
        purpose:
          type: string
          description: |
            The intended purpose of the uploaded file.

            See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose)
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
        mime_type:
          type: string
          description: |
            The MIME type of the file.

            This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision
          x-ballerina-name: mimeType
        bytes:
          type: integer
          description: |
            The number of bytes in the file you are uploading
      additionalProperties: false
    MessageDeltaContentTextAnnotationsFilePathObjectFilePath:
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file that was generated
          x-ballerina-name: fileId
    TranscriptionWord:
      required:
      - end
      - start
      - word
      type: object
      properties:
        start:
          type: number
          description: Start time of the word in seconds
          format: float
        end:
          type: number
          description: End time of the word in seconds
          format: float
        word:
          type: string
          description: The text content of the word
    CreateSpeechRequest:
      required:
      - input
      - model
      - voice
      type: object
      properties:
        voice:
          type: string
          description: "The voice to use when generating the audio. Supported voices\
            \ are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews\
            \ of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options)"
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
        input:
          maxLength: 4096
          type: string
          description: The text to generate audio for. The maximum length is 4096
            characters
        response_format:
          type: string
          description: "The format to audio in. Supported formats are `mp3`, `opus`,\
            \ `aac`, `flac`, `wav`, and `pcm`"
          default: mp3
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          x-ballerina-name: responseFormat
        model:
          description: |
            One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`
          anyOf:
          - type: string
          - type: string
            enum:
            - tts-1
            - tts-1-hd
          x-oaiTypeLabel: string
        speed:
          maximum: 4.0
          minimum: 0.25
          type: number
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default
          default: 1.0
      additionalProperties: false
    AssistantObjectToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    RunStreamEventRunStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.queued
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `queued` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateVectorStoreFileRequest:
      required:
      - file_id
      type: object
      properties:
        chunking_strategy:
          allOf:
          - $ref: '#/components/schemas/ChunkingStrategyRequestParam'
          x-ballerina-name: chunkingStrategy
        file_id:
          type: string
          description: "A [File](/docs/api-reference/files) ID that the vector store\
            \ should use. Useful for tools like `file_search` that can access files"
          x-ballerina-name: fileId
      additionalProperties: false
    MessageStreamEventMessageStreamEventMessageStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageDeltaObject'
        event:
          type: string
          enum:
          - thread.message.delta
      description: "Occurs when parts of a [Message](/docs/api-reference/messages/object)\
        \ are being streamed"
      x-oaiMeta:
        dataDescription: "`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)"
    CreateMessageRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartText:
      title: Text content part
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: The text content
        type:
          type: string
          description: The type of the content part
          enum:
          - text
    ModifyThreadRequest:
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    MessageContentTextObject:
      title: Text
      required:
      - text
      - type
      type: object
      properties:
        text:
          $ref: '#/components/schemas/MessageContentTextObjectText'
        type:
          type: string
          description: Always `text`
          enum:
          - text
      description: The text content that is part of a message
    DeleteMessageResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - thread.message.deleted
    MessageStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/MessageStreamEventOneOf1'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventOneOf12'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventOneOf123'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf1234'
      - $ref: '#/components/schemas/MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf12345'
    RunStepDeltaObjectDelta:
      type: object
      properties:
        step_details:
          type: object
          description: The details of the run step
          oneOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
          x-oaiExpandable: true
          x-ballerina-name: stepDetails
      description: The delta containing the fields that have changed on the run step
    AssistantsNamedToolChoiceFunction:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
    Embedding:
      required:
      - embedding
      - index
      - object
      type: object
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings
        embedding:
          type: array
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings)
          items:
            type: number
        object:
          type: string
          description: "The object type, which is always \"embedding\""
          enum:
          - embedding
      description: |
        Represents an embedding vector returned by embedding endpoint
      x-oaiMeta:
        name: The embedding object
        example: |
          {
            "object": "embedding",
            "embedding": [
              0.0023064255,
              -0.009327292,
              .... (1536 floats total for ada-002)
              -0.0028842222,
            ],
            "index": 0
          }
    ChatCompletionMessageToolCallChunkFunction:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
    RunStepDetailsMessageCreationObjectMessageCreation:
      required:
      - message_id
      type: object
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step
          x-ballerina-name: messageId
    RunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepDeltaObject'
        event:
          type: string
          enum:
          - thread.run.step.delta
      description: "Occurs when parts of a [run step](/docs/api-reference/runs/step-object)\
        \ are being streamed"
      x-oaiMeta:
        dataDescription: "`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)"
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.completed
      description: "Occurs when a [run](/docs/api-reference/runs/object) is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateChatCompletionRequest:
      required:
      - messages
      - model
      type: object
      properties:
        top_logprobs:
          maximum: 20
          minimum: 0
          type: integer
          description: "An integer between 0 and 20 specifying the number of most\
            \ likely tokens to return at each token position, each with an associated\
            \ log probability. `logprobs` must be set to `true` if this parameter\
            \ is used"
          nullable: true
          x-ballerina-name: topLogprobs
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token
          nullable: true
          x-oaiTypeLabel: map
          x-ballerina-name: logitBias
        seed:
          maximum: 9223372036854775807
          minimum: -9223372036854775808
          type: integer
          description: |
            This feature is in Beta.
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
          nullable: true
          x-oaiMeta:
            beta: true
        functions:
          maxItems: 128
          minItems: 1
          type: array
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for
          deprecated: true
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
        max_tokens:
          type: integer
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.

            The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
          nullable: true
          x-ballerina-name: maxTokens
        function_call:
          description: |
            Deprecated in favor of `tool_choice`.

            Controls which (if any) function is called by the model.
            `none` means the model will not call a function and instead generates a message.
            `auto` means the model can pick between generating a message or calling a function.
            Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

            `none` is the default when no functions are present. `auto` is the default if functions are present
          deprecated: true
          oneOf:
          - type: string
            description: |
              `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.
            enum:
            - none
            - auto
          - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          x-oaiExpandable: true
          x-ballerina-name: functionCall
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          nullable: true
          default: 0
          x-ballerina-name: presencePenalty
        tools:
          type: array
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
        "n":
          maximum: 128
          minimum: 1
          type: integer
          description: How many chat completion choices to generate for each input
            message. Note that you will be charged based on the number of generated
            tokens across all of the choices. Keep `n` as `1` to minimize costs
          nullable: true
          example: 1
          default: 1
        logprobs:
          type: boolean
          description: "Whether to return log probabilities of the output tokens or\
            \ not. If true, returns the log probabilities of each output token returned\
            \ in the `content` of `message`"
          nullable: true
          default: false
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          nullable: true
          default: 0
          x-ballerina-name: frequencyPenalty
        response_format:
          allOf:
          - $ref: '#/components/schemas/CreateChatCompletionRequestResponseFormat'
          x-ballerina-name: responseFormat
        stop:
          description: |
            Up to 4 sequences where the API will stop generating further tokens
          oneOf:
          - type: string
            nullable: true
          - maxItems: 4
            minItems: 1
            type: array
            items:
              type: string
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions)
          nullable: true
          default: false
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both
          nullable: true
          example: 1
          default: 1
        messages:
          minItems: 1
          type: array
          description: "A list of messages comprising the conversation so far. [Example\
            \ Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models)"
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
          x-ballerina-name: toolChoice
        model:
          description: "ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)\
            \ table for details on which models work with the Chat API"
          example: gpt-4-turbo
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4o-mini
            - gpt-4o-mini-2024-07-18
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0301
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
          x-oaiTypeLabel: string
        service_tier:
          type: string
          description: |
            Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:
              - If set to 'auto', the system will utilize scale tier credits until they are exhausted.
              - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
              - When not set, the default behavior is 'auto'.

              When this parameter is set, the response body will include the `service_tier` utilized
          nullable: true
          enum:
          - auto
          - default
          x-ballerina-name: serviceTier
        stream_options:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamOptions'
          x-ballerina-name: streamOptions
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
    CreateModerationResponseCategories:
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
      properties:
        self-harm/intent:
          type: boolean
          description: "Content where the speaker expresses that they are engaging\
            \ or intend to engage in acts of self-harm, such as suicide, cutting,\
            \ and eating disorders"
          x-ballerina-name: selfHarmIntent
        hate/threatening:
          type: boolean
          description: "Hateful content that also includes violence or serious harm\
            \ towards the targeted group based on race, gender, ethnicity, religion,\
            \ nationality, sexual orientation, disability status, or caste"
          x-ballerina-name: hateThreatening
        self-harm/instructions:
          type: boolean
          description: "Content that encourages performing acts of self-harm, such\
            \ as suicide, cutting, and eating disorders, or that gives instructions\
            \ or advice on how to commit such acts"
          x-ballerina-name: selfHarmInstructions
        sexual/minors:
          type: boolean
          description: Sexual content that includes an individual who is under 18
            years old
          x-ballerina-name: sexualMinors
        harassment/threatening:
          type: boolean
          description: Harassment content that also includes violence or serious harm
            towards any target
          x-ballerina-name: harassmentThreatening
        hate:
          type: boolean
          description: "Content that expresses, incites, or promotes hate based on\
            \ race, gender, ethnicity, religion, nationality, sexual orientation,\
            \ disability status, or caste. Hateful content aimed at non-protected\
            \ groups (e.g., chess players) is harassment"
        self-harm:
          type: boolean
          description: "Content that promotes, encourages, or depicts acts of self-harm,\
            \ such as suicide, cutting, and eating disorders"
          x-ballerina-name: selfHarm
        harassment:
          type: boolean
          description: "Content that expresses, incites, or promotes harassing language\
            \ towards any target"
        sexual:
          type: boolean
          description: "Content meant to arouse sexual excitement, such as the description\
            \ of sexual activity, or that promotes sexual services (excluding sex\
            \ education and wellness)"
        violence/graphic:
          type: boolean
          description: "Content that depicts death, violence, or physical injury in\
            \ graphic detail"
          x-ballerina-name: violenceGraphic
        violence:
          type: boolean
          description: "Content that depicts death, violence, or physical injury"
      description: "A list of the categories, and whether they are flagged or not"
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234567:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.failed
      description: "Occurs when a [run](/docs/api-reference/runs/object) fails"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    ModifyAssistantRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    MessageDeltaContentTextObjectTextAnnotations:
      oneOf:
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
      x-oaiExpandable: true
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      title: Code interpreter image output
      required:
      - index
      - type
      type: object
      properties:
        image:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObjectImage'
        index:
          type: integer
          description: The index of the output in the outputs array
        type:
          type: string
          description: Always `image`
          enum:
          - image
    MessageDeltaObjectDelta:
      type: object
      properties:
        role:
          type: string
          description: The entity that produced the message. One of `user` or `assistant`
          enum:
          - user
          - assistant
        content:
          type: array
          description: The content of the message in array of text and/or images
          items:
            $ref: '#/components/schemas/MessageDeltaObjectDeltaContent'
      description: The delta containing the fields that have changed on the Message
    CompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion)
          x-ballerina-name: totalTokens
      description: Usage statistics for the completion request
    FinetuneCompletionRequestInput:
      type: object
      properties:
        completion:
          type: string
          description: The desired completion for this training example
        prompt:
          type: string
          description: The input prompt for this training example
      description: The per-line training example of a fine-tuning input file for completions
        models
      x-oaiMeta:
        name: Training format for completions models
        example: |
          {
            "prompt": "What is the answer to 2+2",
            "completion": "4"
          }
    RunToolCallObject:
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunToolCallObjectFunction'
        id:
          type: string
          description: "The ID of the tool call. This ID must be referenced when you\
            \ submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)\
            \ endpoint"
        type:
          type: string
          description: "The type of tool call the output is required for. For now,\
            \ this is always `function`"
          enum:
          - function
      description: Tool call objects
    RunStepDetailsToolCallsObject:
      title: Tool calls
      required:
      - tool_calls
      - type
      type: object
      properties:
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsObjectToolCalls'
          x-ballerina-name: toolCalls
        type:
          type: string
          description: Always `tool_calls`
          enum:
          - tool_calls
      description: Details of the tool call
    VectorStoreObject:
      title: Vector store
      required:
      - created_at
      - file_counts
      - id
      - last_active_at
      - metadata
      - name
      - object
      - status
      - usage_bytes
      type: object
      properties:
        file_counts:
          allOf:
          - $ref: '#/components/schemas/VectorStoreObjectFileCounts'
          x-ballerina-name: fileCounts
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store will
            expire
          nullable: true
          x-ballerina-name: expiresAt
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          x-ballerina-name: expiresAfter
        last_active_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was
            last active
          nullable: true
          x-ballerina-name: lastActiveAt
        usage_bytes:
          type: integer
          description: The total number of bytes used by the files in the vector store
          x-ballerina-name: usageBytes
        name:
          type: string
          description: The name of the vector store
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store was
            created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `vector_store`"
          enum:
          - vector_store
        status:
          type: string
          description: "The status of the vector store, which can be either `expired`,\
            \ `in_progress`, or `completed`. A status of `completed` indicates that\
            \ the vector store is ready for use"
          enum:
          - expired
          - in_progress
          - completed
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool
      x-oaiMeta:
        name: The vector store object
        beta: true
        example: |
          {
            "id": "vs_123",
            "object": "vector_store",
            "created_at": 1698107661,
            "usage_bytes": 123456,
            "last_active_at": 1698107661,
            "name": "my_vector_store",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "cancelled": 0,
              "failed": 0,
              "total": 100
            },
            "metadata": {},
            "last_used_at": 1698107661
          }
    RunToolCallObjectFunction:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments that the model expects you to pass to the function
      description: The function definition
    ModifyThreadRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    CreateCompletionRequest:
      required:
      - model
      - prompt
      type: object
      properties:
        logit_bias:
          type: object
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated
          nullable: true
          x-oaiTypeLabel: map
          x-ballerina-name: logitBias
        seed:
          maximum: 9223372036854775807
          minimum: -9223372036854775808
          type: integer
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
          nullable: true
        max_tokens:
          minimum: 0
          type: integer
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
          nullable: true
          example: 16
          default: 16
          x-ballerina-name: maxTokens
        presence_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          nullable: true
          default: 0
          x-ballerina-name: presencePenalty
        echo:
          type: boolean
          description: |
            Echo back the prompt in addition to the completion
          nullable: true
          default: false
        suffix:
          type: string
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`
          nullable: true
          example: test.
        "n":
          maximum: 128
          minimum: 1
          type: integer
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
          nullable: true
          example: 1
          default: 1
        logprobs:
          maximum: 5
          minimum: 0
          type: integer
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5
          nullable: true
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        frequency_penalty:
          maximum: 2
          minimum: -2
          type: number
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          nullable: true
          default: 0
          x-ballerina-name: frequencyPenalty
        best_of:
          maximum: 20
          minimum: 0
          type: integer
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return – `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
          nullable: true
          default: 1
          x-ballerina-name: bestOf
        stop:
          description: |
            Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence
          nullable: true
          oneOf:
          - type: string
            nullable: true
            example: |2+

            default: <|endoftext|>
          - maxItems: 4
            minItems: 1
            type: array
            items:
              type: string
              example: "[\"\\n\"]"
        stream:
          type: boolean
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions)
          nullable: true
          default: false
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both
          nullable: true
          example: 1
          default: 1
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-3.5-turbo-instruct
            - davinci-002
            - babbage-002
          x-oaiTypeLabel: string
        stream_options:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamOptions'
          x-ballerina-name: streamOptions
        prompt:
          description: |
            The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

            Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document
          nullable: true
          oneOf:
          - type: string
            example: This is a test.
            default: ""
          - type: array
            items:
              type: string
              example: This is a test.
              default: ""
          - minItems: 1
            type: array
            example: "[1212, 318, 257, 1332, 13]"
            items:
              type: integer
          - minItems: 1
            type: array
            example: "[[1212, 318, 257, 1332, 13]]"
            items:
              minItems: 1
              type: array
              items:
                type: integer
          default: <|endoftext|>
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
    CreateCompletionResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the completion was
            created
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model used for completion
        id:
          type: string
          description: A unique identifier for the completion
        choices:
          type: array
          description: The list of completion choices the model generated for the
            input prompt
          items:
            $ref: '#/components/schemas/CreateCompletionResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always \"text_completion\""
          enum:
          - text_completion
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint)
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
    AssistantToolsFunction:
      title: Function tool
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          type: string
          description: "The type of tool being defined: `function`"
          enum:
          - function
    CreateChatCompletionResponseLogprobs:
      required:
      - content
      type: object
      properties:
        content:
          type: array
          description: A list of message content tokens with log probability information
          nullable: true
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
      description: Log probability information for the choice
      nullable: true
    TruncationObject:
      title: Thread Truncation Controls
      required:
      - type
      type: object
      properties:
        last_messages:
          minimum: 1
          type: integer
          description: The number of most recent messages from the thread when constructing
            the context for the run
          nullable: true
          x-ballerina-name: lastMessages
        type:
          type: string
          description: "The truncation strategy to use for the thread. The default\
            \ is `auto`. If set to `last_messages`, the thread will be truncated to\
            \ the n most recent messages in the thread. When set to `auto`, messages\
            \ in the middle of the thread will be dropped to fit the context length\
            \ of the model, `max_prompt_tokens`"
          enum:
          - auto
          - last_messages
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run
    ListThreadsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/ThreadObject'
        first_id:
          type: string
          example: asst_abc123
        last_id:
          type: string
          example: asst_abc456
        has_more:
          type: boolean
          example: false
    ErrorResponse:
      required:
      - error
      type: object
      properties:
        error:
          $ref: '#/components/schemas/Error'
    AssistantsApiResponseFormat:
      type: object
      properties:
        type:
          type: string
          description: Must be one of `text` or `json_object`
          example: json_object
          default: text
          enum:
          - text
          - json_object
      description: |
        An object describing the expected output of the model. If `json_object` only `function` type `tools` are allowed to be passed to the Run. If `text` the model can return text or any value needed
    RunStepDetailsToolCallsObjectToolCalls:
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
      x-oaiExpandable: true
    VectorStoreObjectFileCounts:
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
      properties:
        in_progress:
          type: integer
          description: The number of files that are currently being processed
          x-ballerina-name: inProgress
        total:
          type: integer
          description: The total number of files
        cancelled:
          type: integer
          description: The number of files that were cancelled
        completed:
          type: integer
          description: The number of files that have been successfully processed
        failed:
          type: integer
          description: The number of files that have failed to process
    RunStepDeltaStepDetailsMessageCreationObjectMessageCreation:
      type: object
      properties:
        message_id:
          type: string
          description: The ID of the message that was created by this run step
          x-ballerina-name: messageId
    ListMessagesResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/MessageObject'
        first_id:
          type: string
          example: msg_abc123
        last_id:
          type: string
          example: msg_abc123
        has_more:
          type: boolean
          example: false
    CreateChatCompletionRequestResponseFormat:
      type: object
      properties:
        type:
          type: string
          description: Must be one of `text` or `json_object`
          example: json_object
          default: text
          enum:
          - text
          - json_object
      description: |
        An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length
    FineTuningJobHyperparameters:
      required:
      - n_epochs
      type: object
      properties:
        n_epochs:
          description: |-
            The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
            "auto" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs
          oneOf:
          - type: string
            enum:
            - auto
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
      description: "The hyperparameters used for the fine-tuning job. See the [fine-tuning\
        \ guide](/docs/guides/fine-tuning) for more details"
    ListAssistantsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      properties:
        first_id:
          type: string
          example: asst_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/AssistantObject'
        last_id:
          type: string
          example: asst_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          example: false
          x-ballerina-name: hasMore
        object:
          type: string
          example: list
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698982736,
                "name": "Coding Tutor",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc456",
                "object": "assistant",
                "created_at": 1698982718,
                "name": "My Assistant",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc789",
                "object": "assistant",
                "created_at": 1698982643,
                "name": null,
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": null,
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            ],
            "first_id": "asst_abc123",
            "last_id": "asst_abc789",
            "has_more": false
          }
    ChatCompletionNamedToolChoiceFunction:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
    CreateChatCompletionStreamResponseUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion)
          x-ballerina-name: totalTokens
      description: |
        An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
        When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request
    CreateThreadAndRunRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    ThreadObjectToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/ThreadObjectToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/ThreadObjectToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    MessageRequestContentTextObject:
      title: Text
      required:
      - text
      - type
      type: object
      properties:
        text:
          type: string
          description: Text content to be sent to the model
        type:
          type: string
          description: Always `text`
          enum:
          - text
      description: The text content that is part of a message
    CreateThreadAndRunRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
    RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs:
      type: object
      oneOf:
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
      x-oaiExpandable: true
    CreateTranscriptionResponseJson:
      required:
      - text
      type: object
      properties:
        text:
          type: string
          description: The transcribed text
      description: "Represents a transcription response returned by model, based on\
        \ the provided input"
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: |
          {
            "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
          }
    RunStepCompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run
            step
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run step
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion)
          x-ballerina-name: totalTokens
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`
      nullable: true
    TranscriptionSegment:
      required:
      - avg_logprob
      - compression_ratio
      - end
      - id
      - no_speech_prob
      - seek
      - start
      - temperature
      - text
      - tokens
      type: object
      properties:
        start:
          type: number
          description: Start time of the segment in seconds
          format: float
        temperature:
          type: number
          description: Temperature parameter used for generating the segment
          format: float
        avg_logprob:
          type: number
          description: "Average logprob of the segment. If the value is lower than\
            \ -1, consider the logprobs failed"
          format: float
          x-ballerina-name: avgLogprob
        no_speech_prob:
          type: number
          description: "Probability of no speech in the segment. If the value is higher\
            \ than 1.0 and the `avg_logprob` is below -1, consider this segment silent"
          format: float
          x-ballerina-name: noSpeechProb
        end:
          type: number
          description: End time of the segment in seconds
          format: float
        tokens:
          type: array
          description: Array of token IDs for the text content
          items:
            type: integer
        id:
          type: integer
          description: Unique identifier of the segment
        text:
          type: string
          description: Text content of the segment
        seek:
          type: integer
          description: Seek offset of the segment
        compression_ratio:
          type: number
          description: "Compression ratio of the segment. If the value is greater\
            \ than 2.4, consider the compression failed"
          format: float
          x-ballerina-name: compressionRatio
    DeleteVectorStoreFileResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - vector_store.file.deleted
    CreateImageRequest:
      required:
      - prompt
      type: object
      properties:
        response_format:
          type: string
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`,\
            \ `1792x1024`, or `1024x1792` for `dall-e-3` models"
          nullable: true
          example: 1024x1024
          default: 1024x1024
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1792x1024
          - 1024x1792
        model:
          description: The model to use for image generation
          nullable: true
          example: dall-e-3
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
            - dall-e-3
          default: dall-e-2
          x-oaiTypeLabel: string
        style:
          type: string
          description: "The style of the generated images. Must be one of `vivid`\
            \ or `natural`. Vivid causes the model to lean towards generating hyper-real\
            \ and dramatic images. Natural causes the model to produce more natural,\
            \ less hyper-real looking images. This param is only supported for `dall-e-3`"
          nullable: true
          example: vivid
          default: vivid
          enum:
          - vivid
          - natural
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length
            is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`
          example: A cute baby sea otter
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported"
          nullable: true
          example: 1
          default: 1
        quality:
          type: string
          description: The quality of the image that will be generated. `hd` creates
            images with finer details and greater consistency across the image. This
            param is only supported for `dall-e-3`
          example: standard
          default: standard
          enum:
          - standard
          - hd
    BatchErrors:
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/BatchErrorsData'
        object:
          type: string
          description: "The object type, which is always `list`"
    CancelUploadRequest:
      type: object
      additionalProperties: false
    ChatCompletionToolChoiceOptionOneOf1:
      type: string
      description: |
        `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools
      enum:
      - none
      - auto
      - required
    RunObjectRequiredActionSubmitToolOutputs:
      required:
      - tool_calls
      type: object
      properties:
        tool_calls:
          type: array
          description: A list of the relevant tool calls
          items:
            $ref: '#/components/schemas/RunToolCallObject'
          x-ballerina-name: toolCalls
      description: Details on the tool outputs needed for this run to continue
    ModifyThreadRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    MessageStreamEventMessageStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.in_progress
      description: "Occurs when a [message](/docs/api-reference/messages/object) moves\
        \ to an `in_progress` state"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    CreateTranscriptionRequest:
      required:
      - file
      - model
      type: object
      properties:
        timestamp_granularities[]:
          type: array
          description: |
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency
          items:
            type: string
            enum:
            - word
            - segment
          default:
          - segment
          x-ballerina-name: timestampGranularities
        file:
          type: string
          description: |
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
          format: binary
          x-oaiTypeLabel: file
        response_format:
          type: string
          description: |
            The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`
          default: json
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          x-ballerina-name: responseFormat
        temperature:
          type: number
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
          default: 0
        model:
          description: |
            ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available
          example: whisper-1
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
          x-oaiTypeLabel: string
        language:
          type: string
          description: |
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language
      additionalProperties: false
    RunObjectIncompleteDetails:
      type: object
      properties:
        reason:
          type: string
          description: The reason why the run is incomplete. This will point to which
            specific token limit was reached over the course of the run
          enum:
          - max_completion_tokens
          - max_prompt_tokens
      description: Details on why the run is incomplete. Will be `null` if the run
        is not incomplete
      nullable: true
    RunStepStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.created
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is created"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    MessageContentTextAnnotationsFileCitationObjectFileCitation:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the specific File the citation is from
          x-ballerina-name: fileId
    SubmitToolOutputsRunRequestToolOutputs:
      type: object
      properties:
        output:
          type: string
          description: The output of the tool call to be submitted to continue the
            run
        tool_call_id:
          type: string
          description: The ID of the tool call in the `required_action` object within
            the run object the output is being submitted for
          x-ballerina-name: toolCallId
    ListBatchesResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        first_id:
          type: string
          example: batch_abc123
          x-ballerina-name: firstId
        data:
          type: array
          items:
            $ref: '#/components/schemas/Batch'
        last_id:
          type: string
          example: batch_abc456
          x-ballerina-name: lastId
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
    CreateEmbeddingResponse:
      required:
      - data
      - model
      - object
      - usage
      type: object
      properties:
        data:
          type: array
          description: The list of embeddings generated by the model
          items:
            $ref: '#/components/schemas/Embedding'
        usage:
          $ref: '#/components/schemas/CreateEmbeddingResponseUsage'
        model:
          type: string
          description: The name of the model used to generate the embedding
        object:
          type: string
          description: "The object type, which is always \"list\""
          enum:
          - list
    BatchErrorsData:
      type: object
      properties:
        code:
          type: string
          description: An error code identifying the error type
        param:
          type: string
          description: "The name of the parameter that caused the error, if applicable"
          nullable: true
        line:
          type: integer
          description: "The line number of the input file where the error occurred,\
            \ if applicable"
          nullable: true
        message:
          type: string
          description: A human-readable message providing more details about the error
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      title: Code interpreter log output
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the output in the outputs array
        type:
          type: string
          description: Always `logs`
          enum:
          - logs
        logs:
          type: string
          description: The text output from the Code Interpreter tool call
      description: Text output from the Code Interpreter tool call as part of a run
        step
    CreateThreadRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateThreadRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/CreateThreadRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    BatchRequestOutputError:
      type: object
      properties:
        code:
          type: string
          description: A machine-readable error code
        message:
          type: string
          description: A human-readable error message
      description: "For requests that failed with a non-HTTP error, this will contain\
        \ more information on the cause of the failure"
      nullable: true
    CreateChatCompletionFunctionResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion
            was created
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model used for the chat completion
        id:
          type: string
          description: A unique identifier for the chat completion
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1
          items:
            $ref: '#/components/schemas/CreateChatCompletionFunctionResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always `chat.completion`"
          enum:
          - chat.completion
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input"
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-abc123",
            "object": "chat.completion",
            "created": 1699896916,
            "model": "gpt-4o-mini",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": null,
                  "tool_calls": [
                    {
                      "id": "call_abc123",
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                      }
                    }
                  ]
                },
                "logprobs": null,
                "finish_reason": "tool_calls"
              }
            ],
            "usage": {
              "prompt_tokens": 82,
              "completion_tokens": 17,
              "total_tokens": 99
            }
          }
    RunObject:
      title: A run on a thread
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expires_at
      - failed_at
      - id
      - incomplete_details
      - instructions
      - last_error
      - max_completion_tokens
      - max_prompt_tokens
      - metadata
      - model
      - object
      - parallel_tool_calls
      - required_action
      - response_format
      - started_at
      - status
      - thread_id
      - tool_choice
      - tools
      - truncation_strategy
      - usage
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was cancelled
          nullable: true
          x-ballerina-name: cancelledAt
        instructions:
          type: string
          description: "The instructions that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ used for execution of this run"
          x-ballerina-name: assistantId
        required_action:
          allOf:
          - $ref: '#/components/schemas/RunObjectRequiredAction'
          x-ballerina-name: requiredAction
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was created
          x-ballerina-name: createdAt
        tools:
          maxItems: 20
          type: array
          description: "The list of tools that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
          items:
            $ref: '#/components/schemas/RunObjectTools'
          default: []
        top_p:
          type: number
          description: "The nucleus sampling value used for this run. If not set,\
            \ defaults to 1"
          nullable: true
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run
          nullable: true
          x-ballerina-name: maxCompletionTokens
        thread_id:
          type: string
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ executed on as a part of this run"
          x-ballerina-name: threadId
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run will expire
          nullable: true
          x-ballerina-name: expiresAt
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        temperature:
          type: number
          description: "The sampling temperature used for this run. If not set, defaults\
            \ to 1"
          nullable: true
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          x-ballerina-name: toolChoice
        model:
          type: string
          description: "The model that the [assistant](/docs/api-reference/assistants)\
            \ used for this run"
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/RunObjectLastError'
          x-ballerina-name: lastError
        incomplete_details:
          allOf:
          - $ref: '#/components/schemas/RunObjectIncompleteDetails'
          x-ballerina-name: incompleteDetails
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          x-ballerina-name: truncationStrategy
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was completed
          nullable: true
          x-ballerina-name: completedAt
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        started_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run was started
          nullable: true
          x-ballerina-name: startedAt
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run failed
          nullable: true
          x-ballerina-name: failedAt
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run
          nullable: true
          x-ballerina-name: maxPromptTokens
        object:
          type: string
          description: "The object type, which is always `thread.run`"
          enum:
          - thread.run
        status:
          type: string
          description: "The status of the run, which can be either `queued`, `in_progress`,\
            \ `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\
            \ `incomplete`, or `expired`"
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
      description: "Represents an execution run on a [thread](/docs/api-reference/threads)"
      x-oaiMeta:
        name: The run object
        beta: true
        example: |
          {
            "id": "run_abc123",
            "object": "thread.run",
            "created_at": 1698107661,
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "status": "completed",
            "started_at": 1699073476,
            "expires_at": null,
            "cancelled_at": null,
            "failed_at": null,
            "completed_at": 1699073498,
            "last_error": null,
            "model": "gpt-4-turbo",
            "instructions": null,
            "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
            "metadata": {},
            "incomplete_details": null,
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            },
            "temperature": 1.0,
            "top_p": 1.0,
            "max_prompt_tokens": 1000,
            "max_completion_tokens": 1000,
            "truncation_strategy": {
              "type": "auto",
              "last_messages": null
            },
            "response_format": "auto",
            "tool_choice": "auto",
            "parallel_tool_calls": true
          }
    ChatCompletionRequestUserMessage:
      title: User message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `user`"
          enum:
          - user
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        content:
          description: |
            The contents of the user message
          oneOf:
          - title: Text content
            type: string
            description: The text contents of the message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type, each can\
              \ be of type `text` or `image_url` when passing in images. You can pass\
              \ multiple images by adding multiple `image_url` content parts. Image\
              \ input is only supported when using the `gpt-4o` model."
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPart'
          x-oaiExpandable: true
    MessageDeltaObject:
      title: Message delta object
      required:
      - delta
      - id
      - object
      type: object
      properties:
        delta:
          $ref: '#/components/schemas/MessageDeltaObjectDelta'
        id:
          type: string
          description: "The identifier of the message, which can be referenced in\
            \ API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread.message.delta`"
          enum:
          - thread.message.delta
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: |
          {
            "id": "msg_123",
            "object": "thread.message.delta",
            "delta": {
              "content": [
                {
                  "index": 0,
                  "type": "text",
                  "text": { "value": "Hello", "annotations": [] }
                }
              ]
            }
          }
    AssistantMessage:
      title: Assistant message
      type: object
      properties:
        weight:
          type: integer
          description: Controls whether the assistant message is trained against (0
            or 1)
          enum:
          - 0
          - 1
      deprecated: false
    RunStepDeltaStepDetailsMessageCreationObject:
      title: Message creation
      required:
      - type
      type: object
      properties:
        message_creation:
          allOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObjectMessageCreation'
          x-ballerina-name: messageCreation
        type:
          type: string
          description: Always `message_creation`
          enum:
          - message_creation
      description: Details of the message creation by the run step
    ModifyAssistantRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    ChatCompletionTool:
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
    VectorStoreExpirationAfter:
      title: Vector store expiration policy
      required:
      - anchor
      - days
      type: object
      properties:
        anchor:
          type: string
          description: "Anchor timestamp after which the expiration policy applies.\
            \ Supported anchors: `last_active_at`"
          enum:
          - last_active_at
        days:
          maximum: 365
          minimum: 1
          type: integer
          description: The number of days after the anchor time that the vector store
            will expire
      description: The expiration policy for a vector store
    CreateThreadAndRunRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    AssistantsApiToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tools and instead generates a message.
        `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools before responding to the user.
        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool
      oneOf:
      - $ref: '#/components/schemas/AssistantsApiToolChoiceOptionOneOf1'
      - $ref: '#/components/schemas/AssistantsNamedToolChoice'
      x-oaiExpandable: true
    ModifyMessageRequest:
      type: object
      properties:
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    RunStepStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStepStreamEventOneOf1'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventOneOf12'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf12345'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123456'
      - $ref: '#/components/schemas/RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234567'
    ChatCompletionStreamResponseDelta:
      type: object
      properties:
        role:
          type: string
          description: The role of the author of this message
          enum:
          - system
          - user
          - assistant
          - tool
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionStreamResponseDeltaFunctionCall'
          x-ballerina-name: functionCall
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
          x-ballerina-name: toolCalls
        content:
          type: string
          description: The contents of the chunk message
          nullable: true
      description: A chat completion delta generated by streamed model responses
    RunStepDetailsToolCallsCodeOutputImageObject:
      title: Code Interpreter image output
      required:
      - image
      - type
      type: object
      properties:
        image:
          $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObjectImage'
        type:
          type: string
          description: Always `image`
          enum:
          - image
    RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreterOutputs:
      type: object
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
      x-oaiExpandable: true
    FunctionParameters:
      type: object
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list"
    OpenAIFile:
      title: OpenAIFile
      required:
      - bytes
      - created_at
      - filename
      - id
      - object
      - purpose
      - status
      properties:
        id:
          type: string
          description: "The file identifier, which can be referenced in the API endpoints."
        bytes:
          type: integer
          description: "The size of the file, in bytes."
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the file was created.
        filename:
          type: string
          description: The name of the file.
        object:
          type: string
          description: "The object type, which is always `file`."
          enum:
          - file
        purpose:
          type: string
          description: "The intended purpose of the file. Supported values are `assistants`,\
            \ `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\
            \ and `vision`."
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
        status:
          type: string
          description: "Deprecated. The current status of the file, which can be either\
            \ `uploaded`, `processed`, or `error`."
          deprecated: true
          enum:
          - uploaded
          - processed
          - error
        status_details:
          type: string
          description: "Deprecated. For details on why a fine-tuning training file\
            \ failed validation, see the `error` field on `fine_tuning.job`."
          deprecated: true
      description: The `File` object represents a document that has been uploaded
        to OpenAI
      x-oaiMeta:
        name: The file object
        example: |
          {
            "id": "file-abc123",
            "object": "file",
            "bytes": 120000,
            "created_at": 1677610602,
            "filename": "salesOverview.pdf",
            "purpose": "assistants",
          }
    ModifyAssistantRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    ChatCompletionMessageToolCallChunk:
      required:
      - index
      type: object
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCallChunkFunction'
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
    MessageDeltaContentImageUrlObject:
      title: Image URL
      required:
      - index
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentImageUrlObjectImageUrl'
          x-ballerina-name: imageUrl
        index:
          type: integer
          description: The index of the content part in the message
        type:
          type: string
          description: Always `image_url`
          enum:
          - image_url
      description: References an image URL in the content of a message
    AssistantStreamEvent:
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEvent'
      - $ref: '#/components/schemas/RunStreamEvent'
      - $ref: '#/components/schemas/RunStepStreamEvent'
      - $ref: '#/components/schemas/MessageStreamEvent'
      - $ref: '#/components/schemas/ErrorEvent'
      - $ref: '#/components/schemas/DoneEvent'
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      title: Function tool call
      required:
      - index
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObjectFunction'
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `function`
            for this type of tool call
          enum:
          - function
    RunStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.created
      description: "Occurs when a new [run](/docs/api-reference/runs/object) is created"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateAssistantRequestToolResourcesFileSearchVectorStores:
      type: object
      properties:
        chunking_strategy:
          type: object
          description: "The chunking strategy used to chunk the file(s). If not set,\
            \ will use the `auto` strategy"
          oneOf:
          - title: Auto Chunking Strategy
            required:
            - type
            type: object
            properties:
              type:
                type: string
                description: Always `auto`.
                enum:
                - auto
            additionalProperties: false
            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
              of `800` and `chunk_overlap_tokens` of `400`.
          - title: Static Chunking Strategy
            required:
            - static
            - type
            type: object
            properties:
              type:
                type: string
                description: Always `static`.
                enum:
                - static
              static:
                required:
                - chunk_overlap_tokens
                - max_chunk_size_tokens
                type: object
                properties:
                  max_chunk_size_tokens:
                    maximum: 4096
                    minimum: 100
                    type: integer
                    description: The maximum number of tokens in each chunk. The default
                      value is `800`. The minimum value is `100` and the maximum value
                      is `4096`.
                  chunk_overlap_tokens:
                    type: integer
                    description: |
                      The number of tokens that overlap between chunks. The default value is `400`.

                      Note that the overlap must not exceed half of `max_chunk_size_tokens`.
                additionalProperties: false
            additionalProperties: false
          x-oaiExpandable: true
          x-ballerina-name: chunkingStrategy
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          x-oaiTypeLabel: map
        file_ids:
          maxItems: 10000
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store
          items:
            type: string
          x-ballerina-name: fileIds
    ListVectorStoreFilesResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
        first_id:
          type: string
          example: file-abc123
        last_id:
          type: string
          example: file-abc456
        has_more:
          type: boolean
          example: false
    RunStepDetailsToolCallsCodeOutputImageObjectImage:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: "The [file](/docs/api-reference/files) ID of the image"
          x-ballerina-name: fileId
    ChatCompletionRequestMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
      x-oaiExpandable: true
    Batch:
      required:
      - completion_window
      - created_at
      - endpoint
      - id
      - input_file_id
      - object
      - status
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was cancelled
          x-ballerina-name: cancelledAt
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        request_counts:
          allOf:
          - $ref: '#/components/schemas/BatchRequestCounts'
          x-ballerina-name: requestCounts
        input_file_id:
          type: string
          description: The ID of the input file for the batch
          x-ballerina-name: inputFileId
        output_file_id:
          type: string
          description: The ID of the file containing the outputs of successfully executed
            requests
          x-ballerina-name: outputFileId
        error_file_id:
          type: string
          description: The ID of the file containing the outputs of requests with
            errors
          x-ballerina-name: errorFileId
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was created
          x-ballerina-name: createdAt
        in_progress_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            processing
          x-ballerina-name: inProgressAt
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch expired
          x-ballerina-name: expiredAt
        finalizing_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing
          x-ballerina-name: finalizingAt
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch was completed
          x-ballerina-name: completedAt
        endpoint:
          type: string
          description: The OpenAI API endpoint used by the batch
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch will expire
          x-ballerina-name: expiresAt
        cancelling_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling
          x-ballerina-name: cancellingAt
        completion_window:
          type: string
          description: The time frame within which the batch should be processed
          x-ballerina-name: completionWindow
        id:
          type: string
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the batch failed
          x-ballerina-name: failedAt
        errors:
          $ref: '#/components/schemas/BatchErrors'
        object:
          type: string
          description: "The object type, which is always `batch`"
          enum:
          - batch
        status:
          type: string
          description: The current status of the batch
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
      x-oaiMeta:
        name: The batch object
        example: |
          {
            "id": "batch_abc123",
            "object": "batch",
            "endpoint": "/v1/completions",
            "errors": null,
            "input_file_id": "file-abc123",
            "completion_window": "24h",
            "status": "completed",
            "output_file_id": "file-cvaTdG",
            "error_file_id": "file-HOWS94",
            "created_at": 1711471533,
            "in_progress_at": 1711471538,
            "expires_at": 1711557933,
            "finalizing_at": 1711493133,
            "completed_at": 1711493163,
            "failed_at": null,
            "expired_at": null,
            "cancelling_at": null,
            "cancelled_at": null,
            "request_counts": {
              "total": 100,
              "completed": 95,
              "failed": 5
            },
            "metadata": {
              "customer_id": "user_123456789",
              "batch_description": "Nightly eval job",
            }
          }
    StaticChunkingStrategy:
      required:
      - chunk_overlap_tokens
      - max_chunk_size_tokens
      type: object
      properties:
        max_chunk_size_tokens:
          maximum: 4096
          minimum: 100
          type: integer
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`
          x-ballerina-name: maxChunkSizeTokens
        chunk_overlap_tokens:
          type: integer
          description: |
            The number of tokens that overlap between chunks. The default value is `400`.

            Note that the overlap must not exceed half of `max_chunk_size_tokens`
          x-ballerina-name: chunkOverlapTokens
      additionalProperties: false
    ? RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456789
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.cancelled
      description: "Occurs when a [run](/docs/api-reference/runs/object) is cancelled"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CompleteUploadRequest:
      required:
      - part_ids
      type: object
      properties:
        part_ids:
          type: array
          description: |
            The ordered list of Part IDs
          items:
            type: string
          x-ballerina-name: partIds
        md5:
          type: string
          description: |
            The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect
      additionalProperties: false
    AssistantObjectToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    ChatCompletionStreamResponseDeltaFunctionCall:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      deprecated: true
    MessageContentImageFileObject:
      title: Image file
      required:
      - image_file
      - type
      type: object
      properties:
        image_file:
          allOf:
          - $ref: '#/components/schemas/MessageContentImageFileObjectImageFile'
          x-ballerina-name: imageFile
        type:
          type: string
          description: Always `image_file`
          enum:
          - image_file
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message"
    ThreadObjectToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    CreateTranslationResponse:
      oneOf:
      - $ref: '#/components/schemas/CreateTranslationResponseJson'
      - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
    AssistantObject:
      title: Assistant
      required:
      - created_at
      - description
      - id
      - instructions
      - metadata
      - model
      - name
      - object
      - tools
      type: object
      properties:
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/AssistantObjectToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the assistant was
            created
          x-ballerina-name: createdAt
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/AssistantObjectTools'
          default: []
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        model:
          type: string
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `assistant`"
          enum:
          - assistant
      description: Represents an `assistant` that can call the model and use tools
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: |
          {
            "id": "asst_abc123",
            "object": "assistant",
            "created_at": 1698984975,
            "name": "Math Tutor",
            "description": null,
            "model": "gpt-4-turbo",
            "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
            "tools": [
              {
                "type": "code_interpreter"
              }
            ],
            "metadata": {},
            "top_p": 1.0,
            "temperature": 1.0,
            "response_format": "auto"
          }
    ChatCompletionRequestFunctionMessage:
      title: Function message
      required:
      - content
      - name
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `function`"
          enum:
          - function
        name:
          type: string
          description: The name of the function to call
        content:
          type: string
          description: The contents of the function message
          nullable: true
      deprecated: true
    CreateFileRequest:
      required:
      - file
      - purpose
      type: object
      properties:
        file:
          type: string
          description: |
            The File object (not file name) to be uploaded
          format: binary
        purpose:
          type: string
          description: |
            The intended purpose of the uploaded file.

            Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning)
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
      additionalProperties: false
    ChatCompletionMessageToolCallFunction:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: The function that the model called
    MessageDeltaContentTextAnnotationsFilePathObject:
      title: File path
      required:
      - index
      - type
      type: object
      properties:
        file_path:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObjectFilePath'
          x-ballerina-name: filePath
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        index:
          type: integer
          description: The index of the annotation in the text content part
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_path`
          enum:
          - file_path
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file
    MessageContentTextAnnotationsFilePathObject:
      title: File path
      required:
      - end_index
      - file_path
      - start_index
      - text
      - type
      type: object
      properties:
        file_path:
          allOf:
          - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObjectFilePath'
          x-ballerina-name: filePath
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_path`
          enum:
          - file_path
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file
    CreateThreadAndRunRequest:
      required:
      - assistant_id
      - thread_id
      type: object
      properties:
        instructions:
          type: string
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateThreadAndRunRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run"
          x-ballerina-name: assistantId
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
        tools:
          maxItems: 20
          type: array
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis
          nullable: true
          items:
            $ref: '#/components/schemas/CreateThreadAndRunRequestTools'
        truncation_strategy:
          allOf:
          - $ref: '#/components/schemas/TruncationObject'
          x-ballerina-name: truncationStrategy
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        max_completion_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxCompletionTokens
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        tool_choice:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
          x-ballerina-name: toolChoice
        model:
          description: "The ID of the [Model](/docs/api-reference/models) to be used\
            \ to execute this run. If a value is provided here, it will override the\
            \ model associated with the assistant. If not, the model associated with\
            \ the assistant will be used"
          nullable: true
          example: gpt-4-turbo
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4o-mini
            - gpt-4o-mini-2024-07-18
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
          x-oaiTypeLabel: string
        max_prompt_tokens:
          minimum: 256
          type: integer
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
          nullable: true
          x-ballerina-name: maxPromptTokens
      additionalProperties: false
    RunStepDeltaStepDetailsToolCallsObjectToolCalls:
      oneOf:
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
      - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
      x-oaiExpandable: true
    CreateThreadRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    FineTuningJobEvent:
      required:
      - created_at
      - id
      - level
      - message
      - object
      type: object
      properties:
        level:
          type: string
          enum:
          - info
          - warn
          - error
        created_at:
          type: integer
          x-ballerina-name: createdAt
        id:
          type: string
        message:
          type: string
        object:
          type: string
          enum:
          - fine_tuning.job.event
      description: Fine-tuning job event object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: |
          {
            "object": "fine_tuning.job.event",
            "id": "ftevent-abc123"
            "created_at": 1677610602,
            "level": "info",
            "message": "Created fine-tuning job"
          }
    FineTuningIntegrationWandb:
      required:
      - project
      type: object
      properties:
        name:
          type: string
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name
          nullable: true
        project:
          type: string
          description: |
            The name of the project that the new run will be created under
          example: my-wandb-project
        entity:
          type: string
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used
          nullable: true
        tags:
          type: array
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}"
          items:
            type: string
            example: custom-tag
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run
    AssistantsNamedToolChoice:
      required:
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/AssistantsNamedToolChoiceFunction'
        type:
          type: string
          description: "The type of the tool. If type is `function`, the function\
            \ name must be set"
          enum:
          - function
          - code_interpreter
          - file_search
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool
    ListRunStepsResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/RunStepObject'
        first_id:
          type: string
          example: step_abc123
        last_id:
          type: string
          example: step_abc456
        has_more:
          type: boolean
          example: false
    MessageObject:
      title: The message object
      required:
      - assistant_id
      - attachments
      - completed_at
      - content
      - created_at
      - id
      - incomplete_at
      - incomplete_details
      - metadata
      - object
      - role
      - run_id
      - status
      - thread_id
      type: object
      properties:
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        role:
          type: string
          description: The entity that produced the message. One of `user` or `assistant`
          enum:
          - user
          - assistant
        assistant_id:
          type: string
          description: "If applicable, the ID of the [assistant](/docs/api-reference/assistants)\
            \ that authored this message"
          nullable: true
          x-ballerina-name: assistantId
        run_id:
          type: string
          description: "The ID of the [run](/docs/api-reference/runs) associated with\
            \ the creation of this message. Value is `null` when messages are created\
            \ manually using the create message or create thread endpoints"
          nullable: true
          x-ballerina-name: runId
        attachments:
          type: array
          description: "A list of files attached to the message, and the tools they\
            \ were added to"
          nullable: true
          items:
            $ref: '#/components/schemas/MessageObjectAttachments'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was created
          x-ballerina-name: createdAt
        content:
          type: array
          description: The content of the message in array of text and/or images
          items:
            $ref: '#/components/schemas/MessageObjectContent'
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was completed
          nullable: true
          x-ballerina-name: completedAt
        thread_id:
          type: string
          description: "The [thread](/docs/api-reference/threads) ID that this message\
            \ belongs to"
          x-ballerina-name: threadId
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        incomplete_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete
          nullable: true
          x-ballerina-name: incompleteAt
        incomplete_details:
          allOf:
          - $ref: '#/components/schemas/MessageObjectIncompleteDetails'
          x-ballerina-name: incompleteDetails
        object:
          type: string
          description: "The object type, which is always `thread.message`"
          enum:
          - thread.message
        status:
          type: string
          description: "The status of the message, which can be either `in_progress`,\
            \ `incomplete`, or `completed`"
          enum:
          - in_progress
          - incomplete
          - completed
      description: "Represents a message within a [thread](/docs/api-reference/threads)"
      x-oaiMeta:
        name: The message object
        beta: true
        example: |
          {
            "id": "msg_abc123",
            "object": "thread.message",
            "created_at": 1698983503,
            "thread_id": "thread_abc123",
            "role": "assistant",
            "content": [
              {
                "type": "text",
                "text": {
                  "value": "Hi! How can I help you today?",
                  "annotations": []
                }
              }
            ],
            "assistant_id": "asst_abc123",
            "run_id": "run_abc123",
            "attachments": [],
            "metadata": {}
          }
    CreateFineTuningJobRequest:
      required:
      - model
      - training_file
      type: object
      properties:
        training_file:
          type: string
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
          example: file-abc123
          x-ballerina-name: trainingFile
        seed:
          maximum: 2147483647
          minimum: 0
          type: integer
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you
          nullable: true
          example: 42
        validation_file:
          type: string
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
          nullable: true
          example: file-abc123
          x-ballerina-name: validationFile
        hyperparameters:
          $ref: '#/components/schemas/CreateFineTuningJobRequestHyperparameters'
        model:
          description: |
            The name of the model to fine-tune. You can select one of the
            [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned)
          example: gpt-3.5-turbo
          anyOf:
          - type: string
          - type: string
            enum:
            - babbage-002
            - davinci-002
            - gpt-3.5-turbo
          x-oaiTypeLabel: string
        suffix:
          maxLength: 40
          minLength: 1
          type: string
          description: |
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`
          nullable: true
        integrations:
          type: array
          description: A list of integrations to enable for your fine-tuning job
          nullable: true
          items:
            $ref: '#/components/schemas/CreateFineTuningJobRequestIntegrations'
    CreateTranscriptionResponse:
      oneOf:
      - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
      - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
    MessageContentImageUrlObjectImageUrl:
      required:
      - url
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`. Default value\
            \ is `auto`"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: "The external URL of the image, must be a supported image types:\
            \ jpeg, jpg, png, gif, webp"
          format: uri
    CreateFineTuningJobRequestIntegrations:
      required:
      - type
      - wandb
      type: object
      properties:
        wandb:
          $ref: '#/components/schemas/CreateFineTuningJobRequestWandb'
        type:
          description: |
            The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported
          oneOf:
          - type: string
            enum:
            - wandb
    BatchRequestInput:
      type: object
      properties:
        method:
          type: string
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported
          enum:
          - POST
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch
          x-ballerina-name: customId
        url:
          type: string
          description: "The OpenAI API relative URL to be used for the request. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported"
      description: The per-line object of the batch input file
      x-oaiMeta:
        name: The request input object
        example: |
          {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
    ChatCompletionTokenLogprob:
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
      type: object
      properties:
        top_logprobs:
          type: array
          description: "List of the most likely tokens and their log probability,\
            \ at this token position. In rare cases, there may be fewer than the number\
            \ of requested `top_logprobs` returned"
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprobTopLogprobs'
          x-ballerina-name: topLogprobs
        logprob:
          type: number
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely"
        bytes:
          type: array
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token
          nullable: true
          items:
            type: integer
        token:
          type: string
          description: The token
    AssistantsApiResponseFormatOptionOneOf1:
      type: string
      description: |
        `auto` is the default value
      enum:
      - none
      - auto
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    Image:
      type: object
      properties:
        revised_prompt:
          type: string
          description: "The prompt that was used to generate the image, if there was\
            \ any revision to the prompt"
          x-ballerina-name: revisedPrompt
        b64_json:
          type: string
          description: "The base64-encoded JSON of the generated image, if `response_format`\
            \ is `b64_json`"
          x-ballerina-name: b64Json
        url:
          type: string
          description: "The URL of the generated image, if `response_format` is `url`\
            \ (default)"
      description: Represents the url or the content of an image generated by the
        OpenAI API
      x-oaiMeta:
        name: The image object
        example: |
          {
            "url": "...",
            "revised_prompt": "..."
          }
    RunStepDeltaStepDetailsToolCallsObject:
      title: Tool calls
      required:
      - type
      type: object
      properties:
        tool_calls:
          type: array
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObjectToolCalls'
          x-ballerina-name: toolCalls
        type:
          type: string
          description: Always `tool_calls`
          enum:
          - tool_calls
      description: Details of the tool call
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.incomplete
      description: "Occurs when a [run](/docs/api-reference/runs/object) ends with\
        \ status `incomplete`"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateFineTuningJobRequestHyperparameters:
      type: object
      properties:
        batch_size:
          description: |
            Number of examples in each batch. A larger batch size means that model parameters
            are updated less frequently, but with lower variance
          oneOf:
          - type: string
            enum:
            - auto
          - maximum: 256
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: batchSize
        n_epochs:
          description: |
            The number of epochs to train the model for. An epoch refers to one full cycle
            through the training dataset
          oneOf:
          - type: string
            enum:
            - auto
          - maximum: 50
            minimum: 1
            type: integer
          default: auto
          x-ballerina-name: nEpochs
        learning_rate_multiplier:
          description: |
            Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
            overfitting
          oneOf:
          - type: string
            enum:
            - auto
          - minimum: 0
            exclusiveMinimum: true
            type: number
          default: auto
          x-ballerina-name: learningRateMultiplier
      description: The hyperparameters used for the fine-tuning job
    RunObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: "One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`"
          enum:
          - server_error
          - rate_limit_exceeded
          - invalid_prompt
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this run. Will be `null` if there
        are no errors
      nullable: true
    CreateAssistantRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    CreateTranscriptionResponseVerboseJson:
      required:
      - duration
      - language
      - text
      type: object
      properties:
        duration:
          type: string
          description: The duration of the input audio
        words:
          type: array
          description: Extracted words and their corresponding timestamps
          items:
            $ref: '#/components/schemas/TranscriptionWord'
        language:
          type: string
          description: The language of the input audio
        text:
          type: string
          description: The transcribed text
        segments:
          type: array
          description: Segments of the transcribed text and their corresponding details
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
      description: "Represents a verbose json transcription response returned by model,\
        \ based on the provided input"
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: |
          {
            "task": "transcribe",
            "language": "english",
            "duration": 8.470000267028809,
            "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
            "segments": [
              {
                "id": 0,
                "seek": 0,
                "start": 0.0,
                "end": 3.319999933242798,
                "text": " The beach was a popular spot on a hot summer day.",
                "tokens": [
                  50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                ],
                "temperature": 0.0,
                "avg_logprob": -0.2860786020755768,
                "compression_ratio": 1.2363636493682861,
                "no_speech_prob": 0.00985979475080967
              },
              ...
            ]
          }
    CreateRunRequestTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    MessageDeltaContentImageUrlObjectImageUrl:
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: "The URL of the image, must be a supported image types: jpeg,\
            \ jpg, png, gif, webp"
    CreateTranslationRequest:
      required:
      - file
      - model
      type: object
      properties:
        file:
          type: string
          description: |
            The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
          format: binary
          x-oaiTypeLabel: file
        response_format:
          type: string
          description: |
            The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`
          default: json
          x-ballerina-name: responseFormat
        temperature:
          type: number
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
          default: 0
        model:
          description: |
            ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available
          example: whisper-1
          anyOf:
          - type: string
          - type: string
            enum:
            - whisper-1
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English
      additionalProperties: false
    MessageDeltaContentTextAnnotationsFileCitationObjectFileCitation:
      type: object
      properties:
        quote:
          type: string
          description: The specific quote in the file
        file_id:
          type: string
          description: The ID of the specific File the citation is from
          x-ballerina-name: fileId
    FinetuneChatRequestInputMessages:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    UpdateVectorStoreRequest:
      type: object
      properties:
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          x-ballerina-name: expiresAfter
        name:
          type: string
          description: The name of the vector store
          nullable: true
      additionalProperties: false
    CreateFineTuningJobRequestWandb:
      required:
      - project
      type: object
      properties:
        name:
          type: string
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name
          nullable: true
        project:
          type: string
          description: |
            The name of the project that the new run will be created under
          example: my-wandb-project
        entity:
          type: string
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used
          nullable: true
        tags:
          type: array
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}"
          items:
            type: string
            example: custom-tag
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run
    ChatCompletionFunctions:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64"
        description:
          type: string
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function"
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      deprecated: true
    AddUploadPartRequest:
      required:
      - data
      type: object
      properties:
        data:
          type: string
          description: |
            The chunk of bytes for this Part
          format: binary
      additionalProperties: false
    AssistantToolsCode:
      title: Code interpreter tool
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: "The type of tool being defined: `code_interpreter`"
          enum:
          - code_interpreter
    CreateEmbeddingResponseUsage:
      required:
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: The number of tokens used by the prompt
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: The total number of tokens used by the request
          x-ballerina-name: totalTokens
      description: The usage information for the request
    RunStreamEventRunStreamEventRunStreamEventOneOf123:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.in_progress
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ an `in_progress` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    OtherChunkingStrategyResponseParam:
      title: Other Chunking Strategy
      required:
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `other`
          enum:
          - other
      additionalProperties: false
      description: "This is returned when the chunking strategy is unknown. Typically,\
        \ this is because the file was indexed before the `chunking_strategy` concept\
        \ was introduced in the API"
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.failed
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ fails"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    ChatCompletionRequestMessageContentPartImage:
      title: Image content part
      required:
      - image_url
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImageImageUrl'
          x-ballerina-name: imageUrl
        type:
          type: string
          description: The type of the content part
          enum:
          - image_url
    BatchesBody:
      required:
      - completion_window
      - endpoint
      - input_file_id
      type: object
      properties:
        endpoint:
          type: string
          description: "The endpoint to be used for all requests in the batch. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported. Note that `/v1/embeddings` batches are also restricted to\
            \ a maximum of 50,000 embedding inputs across all requests in the batch"
          enum:
          - /v1/chat/completions
          - /v1/embeddings
          - /v1/completions
        metadata:
          type: object
          additionalProperties:
            type: string
          description: Optional custom metadata for the batch
          nullable: true
        input_file_id:
          type: string
          description: |
            The ID of an uploaded file that contains requests for the new batch.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 100 MB in size
          x-ballerina-name: inputFileId
        completion_window:
          type: string
          description: The time frame within which the batch should be processed.
            Currently only `24h` is supported
          enum:
          - 24h
          x-ballerina-name: completionWindow
    AssistantObjectToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    MessageDeltaContentTextObject:
      title: Text
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message
        text:
          $ref: '#/components/schemas/MessageDeltaContentTextObjectText'
        type:
          type: string
          description: Always `text`
          enum:
          - text
      description: The text content that is part of a message
    CreateVectorStoreFileBatchRequest:
      required:
      - file_ids
      type: object
      properties:
        chunking_strategy:
          allOf:
          - $ref: '#/components/schemas/ChunkingStrategyRequestParam'
          x-ballerina-name: chunkingStrategy
        file_ids:
          maxItems: 500
          minItems: 1
          type: array
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files"
          items:
            type: string
          x-ballerina-name: fileIds
      additionalProperties: false
    ModifyThreadRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/ModifyThreadRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    RunStepDetailsToolCallsCodeObjectCodeInterpreter:
      required:
      - input
      - outputs
      type: object
      properties:
        outputs:
          type: array
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type"
          items:
            $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs'
        input:
          type: string
          description: The input to the Code Interpreter tool call
      description: The Code Interpreter tool call definition
    CreateThreadRequest:
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateThreadRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        messages:
          type: array
          description: "A list of [messages](/docs/api-reference/messages) to start\
            \ the thread with"
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
      additionalProperties: false
    MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.completed
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ completed"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    StaticChunkingStrategyRequestParam:
      title: Static Chunking Strategy
      required:
      - static
      - type
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          type: string
          description: Always `static`
          enum:
          - static
      additionalProperties: false
    ModifyAssistantRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
          items:
            type: string
          x-ballerina-name: vectorStoreIds
    MessageObjectIncompleteDetails:
      required:
      - reason
      type: object
      properties:
        reason:
          type: string
          description: The reason the message is incomplete
          enum:
          - content_filter
          - max_tokens
          - run_cancelled
          - run_expired
          - run_failed
      description: "On an incomplete message, details about why the message is incomplete"
      nullable: true
    VectorStoreFileObject:
      title: Vector store files
      required:
      - created_at
      - id
      - last_error
      - object
      - status
      - usage_bytes
      - vector_store_id
      type: object
      properties:
        chunking_strategy:
          type: object
          description: The strategy used to chunk the file
          oneOf:
          - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
          - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
          x-oaiExpandable: true
          x-ballerina-name: chunkingStrategy
        usage_bytes:
          type: integer
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size
          x-ballerina-name: usageBytes
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store file
            was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/VectorStoreFileObjectLastError'
          x-ballerina-name: lastError
        object:
          type: string
          description: "The object type, which is always `vector_store.file`"
          enum:
          - vector_store.file
        vector_store_id:
          type: string
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to"
          x-ballerina-name: vectorStoreId
        status:
          type: string
          description: "The status of the vector store file, which can be either `in_progress`,\
            \ `completed`, `cancelled`, or `failed`. The status `completed` indicates\
            \ that the vector store file is ready for use"
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
      description: A list of files attached to a vector store
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: |
          {
            "id": "file-abc123",
            "object": "vector_store.file",
            "usage_bytes": 1234,
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "last_error": null,
            "chunking_strategy": {
              "type": "static",
              "static": {
                "max_chunk_size_tokens": 800,
                "chunk_overlap_tokens": 400
              }
            }
          }
    CreateThreadRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
        vector_stores:
          maxItems: 1
          type: array
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            $ref: '#/components/schemas/CreateThreadRequestToolResourcesFileSearchVectorStores'
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
    Upload:
      title: Upload
      required:
      - bytes
      - created_at
      - expires_at
      - filename
      - id
      - purpose
      - status
      - step_number
      type: object
      properties:
        filename:
          type: string
          description: The name of the file to be uploaded
        expires_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created
          x-ballerina-name: expiresAt
        file:
          $ref: '#/components/schemas/OpenAIFile'
        purpose:
          type: string
          description: "The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose)\
            \ for acceptable values"
        bytes:
          type: integer
          description: The intended number of bytes to be uploaded
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Upload was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The Upload unique identifier, which can be referenced in API\
            \ endpoints"
        status:
          type: string
          description: The status of the Upload
          enum:
          - pending
          - completed
          - cancelled
          - expired
        object:
          type: string
          description: "The object type, which is always \"upload\""
          enum:
          - upload
      description: |
        The Upload object can accept byte chunks in the form of Parts
      x-oaiMeta:
        name: The upload object
        example: |
          {
            "id": "upload_abc123",
            "object": "upload",
            "bytes": 2147483648,
            "created_at": 1719184911,
            "filename": "training_examples.jsonl",
            "purpose": "fine-tune",
            "status": "completed",
            "expires_at": 1719127296,
            "file": {
              "id": "file-xyz321",
              "object": "file",
              "bytes": 2147483648,
              "created_at": 1719186911,
              "filename": "training_examples.jsonl",
              "purpose": "fine-tune",
            }
          }
    ThreadStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEventOneOf1'
    VectorStoreFileObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: One of `server_error` or `rate_limit_exceeded`
          enum:
          - internal_error
          - file_not_found
          - parsing_error
          - unhandled_mime_type
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this vector store file. Will be
        `null` if there are no errors
      nullable: true
    FineTuningJobError:
      required:
      - code
      - message
      - param
      type: object
      properties:
        code:
          type: string
          description: A machine-readable error code
        param:
          type: string
          description: "The parameter that was invalid, usually `training_file` or\
            \ `validation_file`. This field will be null if the failure was not parameter-specific"
          nullable: true
        message:
          type: string
          description: A human-readable error message
      description: "For fine-tuning jobs that have `failed`, this will contain more\
        \ information on the cause of the failure"
      nullable: true
    ChunkingStrategyRequestParam:
      type: object
      description: "The chunking strategy used to chunk the file(s). If not set, will\
        \ use the `auto` strategy"
      oneOf:
      - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
      - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      x-oaiExpandable: true
    CreateModerationResponseCategoryScores:
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
      properties:
        self-harm/intent:
          type: number
          description: The score for the category 'self-harm/intent'
          x-ballerina-name: selfHarmIntent
        hate/threatening:
          type: number
          description: The score for the category 'hate/threatening'
          x-ballerina-name: hateThreatening
        self-harm/instructions:
          type: number
          description: The score for the category 'self-harm/instructions'
          x-ballerina-name: selfHarmInstructions
        sexual/minors:
          type: number
          description: The score for the category 'sexual/minors'
          x-ballerina-name: sexualMinors
        harassment/threatening:
          type: number
          description: The score for the category 'harassment/threatening'
          x-ballerina-name: harassmentThreatening
        hate:
          type: number
          description: The score for the category 'hate'
        self-harm:
          type: number
          description: The score for the category 'self-harm'
          x-ballerina-name: selfHarm
        harassment:
          type: number
          description: The score for the category 'harassment'
        sexual:
          type: number
          description: The score for the category 'sexual'
        violence/graphic:
          type: number
          description: The score for the category 'violence/graphic'
          x-ballerina-name: violenceGraphic
        violence:
          type: number
          description: The score for the category 'violence'
      description: A list of the categories along with their scores as predicted by
        model
    RunStepStreamEventRunStepStreamEventOneOf12:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.in_progress
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ moves to an `in_progress` state"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunCompletionUsage:
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
      properties:
        completion_tokens:
          type: integer
          description: Number of completion tokens used over the course of the run
          x-ballerina-name: completionTokens
        prompt_tokens:
          type: integer
          description: Number of prompt tokens used over the course of the run
          x-ballerina-name: promptTokens
        total_tokens:
          type: integer
          description: Total number of tokens used (prompt + completion)
          x-ballerina-name: totalTokens
      description: "Usage statistics related to the run. This value will be `null`\
        \ if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)"
      nullable: true
    MessageContentImageUrlObject:
      title: Image URL
      required:
      - image_url
      - type
      type: object
      properties:
        image_url:
          allOf:
          - $ref: '#/components/schemas/MessageContentImageUrlObjectImageUrl'
          x-ballerina-name: imageUrl
        type:
          type: string
          description: The type of the content part
          enum:
          - image_url
      description: References an image URL in the content of a message
    ChatCompletionResponseMessageFunctionCall:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      deprecated: true
    DeleteModelResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
    ImagesResponse:
      required:
      - created
      - data
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            $ref: '#/components/schemas/Image'
    CreateCompletionResponseChoices:
      required:
      - finish_reason
      - index
      - logprobs
      - text
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            or `content_filter` if content was omitted due to a flag from our content filters
          enum:
          - stop
          - length
          - content_filter
          x-ballerina-name: finishReason
        index:
          type: integer
        text:
          type: string
        logprobs:
          $ref: '#/components/schemas/CreateCompletionResponseLogprobs'
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.completed
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    MessageDeltaContentImageFileObjectImageFile:
      type: object
      properties:
        file_id:
          type: string
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content"
          x-ballerina-name: fileId
        detail:
          type: string
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`"
          default: auto
          enum:
          - auto
          - low
          - high
    CreateChatCompletionStreamResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp
        usage:
          $ref: '#/components/schemas/CreateChatCompletionStreamResponseUsage'
        model:
          type: string
          description: The model to generate the completion
        service_tier:
          type: string
          description: The service tier used for processing the request. This field
            is only included if the `service_tier` parameter is specified in the request
          nullable: true
          example: scale
          enum:
          - scale
          - default
          x-ballerina-name: serviceTier
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has
            the same ID
        choices:
          type: array
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`
          items:
            $ref: '#/components/schemas/CreateChatCompletionStreamResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always `chat.completion.chunk`"
          enum:
          - chat.completion.chunk
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input"
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
    ? RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf1234567
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.expired
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ expires"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    CreateChatCompletionFunctionResponseChoices:
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function
          enum:
          - stop
          - length
          - function_call
          - content_filter
          x-ballerina-name: finishReason
        index:
          type: integer
          description: The index of the choice in the list of choices
        message:
          $ref: '#/components/schemas/ChatCompletionResponseMessage'
    ChatCompletionMessageToolCall:
      required:
      - function
      - id
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionMessageToolCallFunction'
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObjectImage:
      type: object
      properties:
        file_id:
          type: string
          description: "The [file](/docs/api-reference/files) ID of the image"
          x-ballerina-name: fileId
    VectorStoreFileBatchObjectFileCounts:
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
      properties:
        in_progress:
          type: integer
          description: The number of files that are currently being processed
          x-ballerina-name: inProgress
        total:
          type: integer
          description: The total number of files
        cancelled:
          type: integer
          description: The number of files that where cancelled
        completed:
          type: integer
          description: The number of files that have been processed
        failed:
          type: integer
          description: The number of files that have failed to process
    CreateImageEditRequest:
      required:
      - image
      - prompt
      type: object
      properties:
        image:
          type: string
          description: "The image to edit. Must be a valid PNG file, less than 4MB,\
            \ and square. If mask is not provided, image must have transparency, which\
            \ will be used as the mask"
          format: binary
        response_format:
          type: string
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`"
          nullable: true
          example: 1024x1024
          default: 1024x1024
          enum:
          - 256x256
          - 512x512
          - 1024x1024
        model:
          description: The model to use for image generation. Only `dall-e-2` is supported
            at this time
          nullable: true
          example: dall-e-2
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
          default: dall-e-2
          x-oaiTypeLabel: string
        prompt:
          type: string
          description: A text description of the desired image(s). The maximum length
            is 1000 characters
          example: A cute baby sea otter wearing a beret
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: The number of images to generate. Must be between 1 and 10
          nullable: true
          example: 1
          default: 1
        mask:
          type: string
          description: "An additional image whose fully transparent areas (e.g. where\
            \ alpha is zero) indicate where `image` should be edited. Must be a valid\
            \ PNG file, less than 4MB, and have the same dimensions as `image`"
          format: binary
    MessageDeltaContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
      - index
      - type
      type: object
      properties:
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        file_citation:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObjectFileCitation'
          x-ballerina-name: fileCitation
        index:
          type: integer
          description: The index of the annotation in the text content part
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_citation`
          enum:
          - file_citation
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files
    AssistantToolsFileSearchFileSearch:
      type: object
      properties:
        max_num_results:
          maximum: 50
          minimum: 1
          type: integer
          description: |
            The maximum number of results the file search tool should output. The default is 20 for gpt-4* models and 5 for gpt-3.5-turbo. This number should be between 1 and 50 inclusive.

            Note that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search/number-of-chunks-returned) for more information
          x-ballerina-name: maxNumResults
      description: Overrides for the file search tool
    ListModelsResponse:
      required:
      - data
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
        object:
          type: string
          enum:
          - list
    ChatCompletionRole:
      type: string
      description: The role of the author of a message
      enum:
      - system
      - user
      - assistant
      - tool
      - function
    AssistantObjectTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    CreateThreadRequestToolResourcesFileSearchVectorStores:
      type: object
      properties:
        chunking_strategy:
          type: object
          description: "The chunking strategy used to chunk the file(s). If not set,\
            \ will use the `auto` strategy"
          oneOf:
          - title: Auto Chunking Strategy
            required:
            - type
            type: object
            properties:
              type:
                type: string
                description: Always `auto`.
                enum:
                - auto
            additionalProperties: false
            description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
              of `800` and `chunk_overlap_tokens` of `400`.
          - title: Static Chunking Strategy
            required:
            - static
            - type
            type: object
            properties:
              type:
                type: string
                description: Always `static`.
                enum:
                - static
              static:
                required:
                - chunk_overlap_tokens
                - max_chunk_size_tokens
                type: object
                properties:
                  max_chunk_size_tokens:
                    maximum: 4096
                    minimum: 100
                    type: integer
                    description: The maximum number of tokens in each chunk. The default
                      value is `800`. The minimum value is `100` and the maximum value
                      is `4096`.
                  chunk_overlap_tokens:
                    type: integer
                    description: |
                      The number of tokens that overlap between chunks. The default value is `400`.

                      Note that the overlap must not exceed half of `max_chunk_size_tokens`.
                additionalProperties: false
            additionalProperties: false
          x-oaiExpandable: true
          x-ballerina-name: chunkingStrategy
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          x-oaiTypeLabel: map
        file_ids:
          maxItems: 10000
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store
          items:
            type: string
          x-ballerina-name: fileIds
    Model:
      title: Model
      required:
      - created
      - id
      - object
      - owned_by
      properties:
        id:
          type: string
          description: "The model identifier, which can be referenced in the API endpoints."
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: "The object type, which is always \"model\"."
          enum:
          - model
        owned_by:
          type: string
          description: The organization that owns the model.
      description: Describes an OpenAI model offering that can be used with the API
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    ErrorEvent:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/Error'
        event:
          type: string
          enum:
          - error
      description: "Occurs when an [error](/docs/guides/error-codes/api-errors) occurs.\
        \ This can happen due to an internal server error or a timeout"
      x-oaiMeta:
        dataDescription: "`data` is an [error](/docs/guides/error-codes/api-errors)"
    ListFilesResponse:
      required:
      - data
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/OpenAIFile'
        object:
          type: string
          enum:
          - list
    CreateChatCompletionStreamResponseChoices:
      required:
      - delta
      - finish_reason
      - index
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function
          nullable: true
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          x-ballerina-name: finishReason
        delta:
          $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
        index:
          type: integer
          description: The index of the choice in the list of choices
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionStreamResponseLogprobs'
    FineTuneChatCompletionRequestAssistantMessage:
      required:
      - role
      allOf:
      - $ref: '#/components/schemas/AssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
    CreateVectorStoreRequest:
      type: object
      properties:
        chunking_strategy:
          type: object
          description: "The chunking strategy used to chunk the file(s). If not set,\
            \ will use the `auto` strategy. Only applicable if `file_ids` is non-empty"
          oneOf:
          - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
          - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
          x-oaiExpandable: true
          x-ballerina-name: chunkingStrategy
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        expires_after:
          allOf:
          - $ref: '#/components/schemas/VectorStoreExpirationAfter'
          x-ballerina-name: expiresAfter
        file_ids:
          maxItems: 500
          type: array
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files"
          items:
            type: string
          x-ballerina-name: fileIds
        name:
          type: string
          description: The name of the vector store
      additionalProperties: false
    ThreadObject:
      title: Thread
      required:
      - created_at
      - id
      - metadata
      - object
      - tool_resources
      type: object
      properties:
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ThreadObjectToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the thread was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread`"
          enum:
          - thread
      description: "Represents a thread that contains [messages](/docs/api-reference/messages)"
      x-oaiMeta:
        name: The thread object
        beta: true
        example: |
          {
            "id": "thread_abc123",
            "object": "thread",
            "created_at": 1698107661,
            "metadata": {}
          }
    CreateChatCompletionResponseChoices:
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
      properties:
        finish_reason:
          type: string
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          x-ballerina-name: finishReason
        index:
          type: integer
          description: The index of the choice in the list of choices
        message:
          $ref: '#/components/schemas/ChatCompletionResponseMessage'
        logprobs:
          $ref: '#/components/schemas/CreateChatCompletionResponseLogprobs'
    ChatCompletionStreamOptions:
      type: object
      properties:
        include_usage:
          type: boolean
          description: |
            If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value
          x-ballerina-name: includeUsage
      description: |
        Options for streaming response. Only set this when you set `stream: true`
      nullable: true
    MessageContentTextAnnotationsFileCitationObject:
      title: File citation
      required:
      - end_index
      - file_citation
      - start_index
      - text
      - type
      type: object
      properties:
        start_index:
          minimum: 0
          type: integer
          x-ballerina-name: startIndex
        file_citation:
          allOf:
          - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObjectFileCitation'
          x-ballerina-name: fileCitation
        end_index:
          minimum: 0
          type: integer
          x-ballerina-name: endIndex
        text:
          type: string
          description: The text in the message content that needs to be replaced
        type:
          type: string
          description: Always `file_citation`
          enum:
          - file_citation
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files
    MessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventMessageStreamEventOneOf12345:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.incomplete
      description: "Occurs when a [message](/docs/api-reference/messages/object) ends\
        \ before it is completed"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ListPaginatedFineTuningJobsResponse:
      required:
      - data
      - has_more
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJob'
        has_more:
          type: boolean
          x-ballerina-name: hasMore
        object:
          type: string
          enum:
          - list
    ? RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678910
    : required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.expired
      description: "Occurs when a [run](/docs/api-reference/runs/object) expires"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    ModifyAssistantRequest:
      type: object
      properties:
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/ModifyAssistantRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
          anyOf:
          - type: string
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/ModifyAssistantRequestTools'
          default: []
      additionalProperties: false
    FineTuningJobCheckpointMetrics:
      type: object
      properties:
        full_valid_mean_token_accuracy:
          type: number
          x-ballerina-name: fullValidMeanTokenAccuracy
        valid_loss:
          type: number
          x-ballerina-name: validLoss
        full_valid_loss:
          type: number
          x-ballerina-name: fullValidLoss
        train_mean_token_accuracy:
          type: number
          x-ballerina-name: trainMeanTokenAccuracy
        valid_mean_token_accuracy:
          type: number
          x-ballerina-name: validMeanTokenAccuracy
        train_loss:
          type: number
          x-ballerina-name: trainLoss
        step:
          type: number
      description: Metrics at the step number during the fine-tuning job
    FinetuneChatRequestInput:
      type: object
      properties:
        parallel_tool_calls:
          allOf:
          - $ref: '#/components/schemas/ParallelToolCalls'
          x-ballerina-name: parallelToolCalls
        functions:
          maxItems: 128
          minItems: 1
          type: array
          description: A list of functions the model may generate JSON inputs for
          deprecated: true
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
        messages:
          minItems: 1
          type: array
          items:
            $ref: '#/components/schemas/FinetuneChatRequestInputMessages'
        tools:
          type: array
          description: A list of tools the model may generate JSON inputs for
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
      description: The per-line training example of a fine-tuning input file for chat
        models
      x-oaiMeta:
        name: Training format for chat models
        example: |
          {
            "messages": [
              { "role": "user", "content": "What is the weather in San Francisco?" },
              {
                "role": "assistant",
                "tool_calls": [
                  {
                    "id": "call_id",
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "arguments": "{\"location\": \"San Francisco, USA\", \"format\": \"celsius\"}"
                    }
                  }
                ]
              }
            ],
            "parallel_tool_calls": false,
            "tools": [
              {
                "type": "function",
                "function": {
                  "name": "get_current_weather",
                  "description": "Get the current weather",
                  "parameters": {
                    "type": "object",
                    "properties": {
                      "location": {
                          "type": "string",
                          "description": "The city and country, eg. San Francisco, USA"
                      },
                      "format": { "type": "string", "enum": ["celsius", "fahrenheit"] }
                    },
                    "required": ["location", "format"]
                  }
                }
              }
            ]
          }
    MessageContentTextObjectTextAnnotations:
      oneOf:
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
      - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
      x-oaiExpandable: true
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.cancelling
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `cancelling` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    BatchRequestOutputResponse:
      type: object
      properties:
        status_code:
          type: integer
          description: The HTTP status code of the response
          x-ballerina-name: statusCode
        body:
          type: object
          description: The JSON body of the response
          x-oaiTypeLabel: map
        request_id:
          type: string
          description: An unique identifier for the OpenAI API request. Please include
            this request ID when contacting support
          x-ballerina-name: requestId
      nullable: true
    ChatCompletionRequestAssistantMessage:
      title: Assistant message
      required:
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `assistant`"
          enum:
          - assistant
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageFunctionCall'
          x-ballerina-name: functionCall
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        tool_calls:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
          x-ballerina-name: toolCalls
        content:
          type: string
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified
          nullable: true
    RunStepDeltaObject:
      title: Run step delta object
      required:
      - delta
      - id
      - object
      type: object
      properties:
        delta:
          $ref: '#/components/schemas/RunStepDeltaObjectDelta'
        id:
          type: string
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints"
        object:
          type: string
          description: "The object type, which is always `thread.run.step.delta`"
          enum:
          - thread.run.step.delta
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: |
          {
            "id": "step_123",
            "object": "thread.run.step.delta",
            "delta": {
              "step_details": {
                "type": "tool_calls",
                "tool_calls": [
                  {
                    "index": 0,
                    "id": "call_123",
                    "type": "code_interpreter",
                    "code_interpreter": { "input": "", "outputs": [] }
                  }
                ]
              }
            }
          }
    ListVectorStoresResponse:
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      properties:
        object:
          type: string
          example: list
        data:
          type: array
          items:
            $ref: '#/components/schemas/VectorStoreObject'
        first_id:
          type: string
          example: vs_abc123
        last_id:
          type: string
          example: vs_abc456
        has_more:
          type: boolean
          example: false
    RunStepObjectLastError:
      required:
      - code
      - message
      type: object
      properties:
        code:
          type: string
          description: One of `server_error` or `rate_limit_exceeded`
          enum:
          - server_error
          - rate_limit_exceeded
        message:
          type: string
          description: A human-readable description of the error
      description: The last error associated with this run step. Will be `null` if
        there are no errors
      nullable: true
    RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter:
      type: object
      properties:
        outputs:
          type: array
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type"
          items:
            $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreterOutputs'
        input:
          type: string
          description: The input to the Code Interpreter tool call
      description: The Code Interpreter tool call definition
    RunStepDetailsToolCallsCodeObject:
      title: Code Interpreter tool call
      required:
      - code_interpreter
      - id
      - type
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObjectCodeInterpreter'
          x-ballerina-name: codeInterpreter
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call
          enum:
          - code_interpreter
      description: Details of the Code Interpreter tool call the run step was involved
        in
    RunObjectTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearch'
      - $ref: '#/components/schemas/AssistantToolsFunction'
      x-oaiExpandable: true
    CreateModerationResponse:
      required:
      - id
      - model
      - results
      type: object
      properties:
        model:
          type: string
          description: The model used to generate the moderation results
        id:
          type: string
          description: The unique identifier for the moderation request
        results:
          type: array
          description: A list of moderation objects
          items:
            $ref: '#/components/schemas/CreateModerationResponseResults'
      description: Represents if a given text input is potentially harmful
      x-oaiMeta:
        name: The moderation object
        example: |
          {
            "id": "modr-XXXXX",
            "model": "text-moderation-005",
            "results": [
              {
                "flagged": true,
                "categories": {
                  "sexual": false,
                  "hate": false,
                  "harassment": false,
                  "self-harm": false,
                  "sexual/minors": false,
                  "hate/threatening": false,
                  "violence/graphic": false,
                  "self-harm/intent": false,
                  "self-harm/instructions": false,
                  "harassment/threatening": true,
                  "violence": true,
                },
                "category_scores": {
                  "sexual": 1.2282071e-06,
                  "hate": 0.010696256,
                  "harassment": 0.29842457,
                  "self-harm": 1.5236925e-08,
                  "sexual/minors": 5.7246268e-08,
                  "hate/threatening": 0.0060676364,
                  "violence/graphic": 4.435014e-06,
                  "self-harm/intent": 8.098441e-10,
                  "self-harm/instructions": 2.8498655e-11,
                  "harassment/threatening": 0.63055265,
                  "violence": 0.99011886,
                }
              }
            ]
          }
    FineTuningIntegration:
      title: Fine-Tuning Job Integration
      required:
      - type
      - wandb
      type: object
      properties:
        wandb:
          $ref: '#/components/schemas/FineTuningIntegrationWandb'
        type:
          type: string
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
    SubmitToolOutputsRunRequest:
      required:
      - tool_outputs
      type: object
      properties:
        stream:
          type: boolean
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message
          nullable: true
        tool_outputs:
          type: array
          description: A list of tools for which the outputs are being submitted
          items:
            $ref: '#/components/schemas/SubmitToolOutputsRunRequestToolOutputs'
          x-ballerina-name: toolOutputs
      additionalProperties: false
    VectorStoreFileBatchObject:
      title: Vector store file batch
      required:
      - created_at
      - file_counts
      - id
      - object
      - status
      - vector_store_id
      type: object
      properties:
        file_counts:
          allOf:
          - $ref: '#/components/schemas/VectorStoreFileBatchObjectFileCounts'
          x-ballerina-name: fileCounts
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The identifier, which can be referenced in API endpoints"
        object:
          type: string
          description: "The object type, which is always `vector_store.file_batch`"
          enum:
          - vector_store.files_batch
        vector_store_id:
          type: string
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to"
          x-ballerina-name: vectorStoreId
        status:
          type: string
          description: "The status of the vector store files batch, which can be either\
            \ `in_progress`, `completed`, `cancelled` or `failed`"
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
      description: A batch of files attached to a vector store
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: |
          {
            "id": "vsfb_123",
            "object": "vector_store.files_batch",
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "failed": 0,
              "cancelled": 0,
              "total": 100
            }
          }
    MessageContentTextAnnotationsFilePathObjectFilePath:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file that was generated
          x-ballerina-name: fileId
    ModifyRunRequest:
      type: object
      properties:
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
      additionalProperties: false
    CreateThreadAndRunRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateThreadAndRunRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/CreateThreadAndRunRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    ChatCompletionFunctionCallOption:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function
    FineTuningJob:
      title: FineTuningJob
      required:
      - created_at
      - error
      - fine_tuned_model
      - finished_at
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - seed
      - status
      - trained_tokens
      - training_file
      - validation_file
      type: object
      properties:
        training_file:
          type: string
          description: "The file ID used for training. You can retrieve the training\
            \ data with the [Files API](/docs/api-reference/files/retrieve-contents)"
          x-ballerina-name: trainingFile
        result_files:
          type: array
          description: "The compiled results file ID(s) for the fine-tuning job. You\
            \ can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)"
          items:
            type: string
            example: file-abc123
          x-ballerina-name: resultFiles
        finished_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: finishedAt
        seed:
          type: integer
          description: The seed used for the fine-tuning job
        fine_tuned_model:
          type: string
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: fineTunedModel
        validation_file:
          type: string
          description: "The file ID used for validation. You can retrieve the validation\
            \ results with the [Files API](/docs/api-reference/files/retrieve-contents)"
          nullable: true
          x-ballerina-name: validationFile
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created
          x-ballerina-name: createdAt
        error:
          $ref: '#/components/schemas/FineTuningJobError'
        estimated_finish:
          type: integer
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running
          nullable: true
          x-ballerina-name: estimatedFinish
        organization_id:
          type: string
          description: The organization that owns the fine-tuning job
          x-ballerina-name: organizationId
        hyperparameters:
          $ref: '#/components/schemas/FineTuningJobHyperparameters'
        model:
          type: string
          description: The base model that is being fine-tuned
        id:
          type: string
          description: "The object identifier, which can be referenced in the API\
            \ endpoints"
        trained_tokens:
          type: integer
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running
          nullable: true
          x-ballerina-name: trainedTokens
        integrations:
          maxItems: 5
          type: array
          description: A list of integrations to enable for this fine-tuning job
          nullable: true
          items:
            $ref: '#/components/schemas/FineTuningJobIntegrations'
        object:
          type: string
          description: "The object type, which is always \"fine_tuning.job\""
          enum:
          - fine_tuning.job
        status:
          type: string
          description: "The current status of the fine-tuning job, which can be either\
            \ `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`"
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API
      x-oaiMeta:
        name: The fine-tuning job object
        example: |
          {
            "object": "fine_tuning.job",
            "id": "ftjob-abc123",
            "model": "davinci-002",
            "created_at": 1692661014,
            "finished_at": 1692661190,
            "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
            "organization_id": "org-123",
            "result_files": [
                "file-abc123"
            ],
            "status": "succeeded",
            "validation_file": null,
            "training_file": "file-abc123",
            "hyperparameters": {
                "n_epochs": 4,
                "batch_size": 1,
                "learning_rate_multiplier": 1.0
            },
            "trained_tokens": 5768,
            "integrations": [],
            "seed": 0,
            "estimated_finish": 0
          }
    RunStepDeltaStepDetailsToolCallsFunctionObjectFunction:
      type: object
      properties:
        output:
          type: string
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet"
          nullable: true
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments passed to the function
      description: The definition of the function that was called
    ChatCompletionRequestSystemMessage:
      title: System message
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `system`"
          enum:
          - system
        name:
          type: string
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role
        content:
          type: string
          description: The contents of the system message
    CreateTranslationResponseVerboseJson:
      required:
      - duration
      - language
      - text
      type: object
      properties:
        duration:
          type: string
          description: The duration of the input audio
        language:
          type: string
          description: The language of the output translation (always `english`)
        text:
          type: string
          description: The translated text
        segments:
          type: array
          description: Segments of the translated text and their corresponding details
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
    MessageContentTextObjectText:
      required:
      - annotations
      - value
      type: object
      properties:
        annotations:
          type: array
          items:
            $ref: '#/components/schemas/MessageContentTextObjectTextAnnotations'
        value:
          type: string
          description: The data that makes up the text
    MessageObjectAttachments:
      type: object
      properties:
        file_id:
          type: string
          description: The ID of the file to attach to the message
          x-ballerina-name: fileId
        tools:
          type: array
          description: The tools to add this file to
          items:
            $ref: '#/components/schemas/MessageObjectTools'
    CreateChatCompletionImageResponse:
      type: object
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input"
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-4o-mini",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
              },
              "logprobs": null,
              "finish_reason": "stop"
            }],
            "usage": {
              "prompt_tokens": 9,
              "completion_tokens": 12,
              "total_tokens": 21
            }
          }
    RunStreamEvent:
      oneOf:
      - $ref: '#/components/schemas/RunStreamEventOneOf1'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventOneOf12'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventOneOf123'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234567'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf123456789'
      - $ref: '#/components/schemas/RunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf12345678910'
    CreateCompletionResponseLogprobs:
      type: object
      properties:
        top_logprobs:
          type: array
          items:
            type: object
            additionalProperties:
              type: number
          x-ballerina-name: topLogprobs
        token_logprobs:
          type: array
          items:
            type: number
          x-ballerina-name: tokenLogprobs
        tokens:
          type: array
          items:
            type: string
        text_offset:
          type: array
          items:
            type: integer
          x-ballerina-name: textOffset
      nullable: true
    FineTuningJobIntegrations:
      oneOf:
      - $ref: '#/components/schemas/FineTuningIntegration'
      x-oaiExpandable: true
    DeleteFileResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - file
    RunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventRunStepStreamEventOneOf123456:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunStepObject'
        event:
          type: string
          enum:
          - thread.run.step.cancelled
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is cancelled"
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    ListFineTuningJobEventsResponse:
      required:
      - data
      - object
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
        object:
          type: string
          enum:
          - list
    CreateMessageRequest:
      required:
      - content
      - role
      type: object
      properties:
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        role:
          type: string
          description: |
            The role of the entity that is creating the message. Allowed values include:
            - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
            - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation
          enum:
          - user
          - assistant
        attachments:
          required:
          - file_id
          - tools
          type: array
          description: "A list of files attached to the message, and the tools they\
            \ should be added to"
          nullable: true
          items:
            $ref: '#/components/schemas/CreateMessageRequestAttachments'
        content:
          oneOf:
          - title: Text content
            type: string
            description: The text contents of the message.
          - title: Array of content parts
            minItems: 1
            type: array
            description: "An array of content parts with a defined type, each can\
              \ be of type `text` or images can be passed with `image_url` or `image_file`.\
              \ Image types are only supported on [Vision-compatible models](/docs/models/overview)."
            items:
              oneOf:
              - $ref: '#/components/schemas/MessageContentImageFileObject'
              - $ref: '#/components/schemas/MessageContentImageUrlObject'
              - $ref: '#/components/schemas/MessageRequestContentTextObject'
              x-oaiExpandable: true
          x-oaiExpandable: true
      additionalProperties: false
    CreateAssistantRequestToolResourcesFileSearch:
      type: object
      properties:
        vector_store_ids:
          maxItems: 1
          type: array
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
        vector_stores:
          maxItems: 1
          type: array
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            $ref: '#/components/schemas/CreateAssistantRequestToolResourcesFileSearchVectorStores'
      oneOf:
      - required:
        - vector_store_ids
      - required:
        - vector_stores
    RunStepObject:
      title: Run steps
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expired_at
      - failed_at
      - id
      - last_error
      - metadata
      - object
      - run_id
      - status
      - step_details
      - thread_id
      - type
      - usage
      type: object
      properties:
        cancelled_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was cancelled
          nullable: true
          x-ballerina-name: cancelledAt
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        assistant_id:
          type: string
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ associated with the run step"
          x-ballerina-name: assistantId
        run_id:
          type: string
          description: "The ID of the [run](/docs/api-reference/runs) that this run\
            \ step is a part of"
          x-ballerina-name: runId
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step was created
          x-ballerina-name: createdAt
        expired_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired
          nullable: true
          x-ballerina-name: expiredAt
        type:
          type: string
          description: "The type of run step, which can be either `message_creation`\
            \ or `tool_calls`"
          enum:
          - message_creation
          - tool_calls
        step_details:
          type: object
          description: The details of the run step
          oneOf:
          - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
          - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
          x-oaiExpandable: true
          x-ballerina-name: stepDetails
        completed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step completed
          nullable: true
          x-ballerina-name: completedAt
        thread_id:
          type: string
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ run"
          x-ballerina-name: threadId
        id:
          type: string
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints"
        last_error:
          allOf:
          - $ref: '#/components/schemas/RunStepObjectLastError'
          x-ballerina-name: lastError
        failed_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the run step failed
          nullable: true
          x-ballerina-name: failedAt
        object:
          type: string
          description: "The object type, which is always `thread.run.step`"
          enum:
          - thread.run.step
        status:
          type: string
          description: "The status of the run step, which can be either `in_progress`,\
            \ `cancelled`, `failed`, `completed`, or `expired`"
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
      description: |
        Represents a step in execution of a run
      x-oaiMeta:
        name: The run step object
        beta: true
        example: |
          {
            "id": "step_abc123",
            "object": "thread.run.step",
            "created_at": 1699063291,
            "run_id": "run_abc123",
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "type": "message_creation",
            "status": "completed",
            "cancelled_at": null,
            "completed_at": 1699063291,
            "expired_at": null,
            "failed_at": null,
            "last_error": null,
            "step_details": {
              "type": "message_creation",
              "message_creation": {
                "message_id": "msg_abc123"
              }
            },
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            }
          }
    ChatCompletionNamedToolChoice:
      required:
      - function
      - type
      type: object
      properties:
        function:
          $ref: '#/components/schemas/ChatCompletionNamedToolChoiceFunction'
        type:
          type: string
          description: "The type of the tool. Currently, only `function` is supported"
          enum:
          - function
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function
    CreateModerationResponseResults:
      required:
      - categories
      - category_scores
      - flagged
      type: object
      properties:
        category_scores:
          allOf:
          - $ref: '#/components/schemas/CreateModerationResponseCategoryScores'
          x-ballerina-name: categoryScores
        flagged:
          type: boolean
          description: Whether any of the below categories are flagged
        categories:
          $ref: '#/components/schemas/CreateModerationResponseCategories'
    MessageObjectContent:
      oneOf:
      - $ref: '#/components/schemas/MessageContentImageFileObject'
      - $ref: '#/components/schemas/MessageContentImageUrlObject'
      - $ref: '#/components/schemas/MessageContentTextObject'
      x-oaiExpandable: true
    MessageDeltaContentImageFileObject:
      title: Image file
      required:
      - index
      - type
      type: object
      properties:
        index:
          type: integer
          description: The index of the content part in the message
        image_file:
          allOf:
          - $ref: '#/components/schemas/MessageDeltaContentImageFileObjectImageFile'
          x-ballerina-name: imageFile
        type:
          type: string
          description: Always `image_file`
          enum:
          - image_file
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message"
    RunStepDetailsToolCallsFunctionObjectFunction:
      required:
      - arguments
      - name
      - output
      type: object
      properties:
        output:
          type: string
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet"
          nullable: true
        name:
          type: string
          description: The name of the function
        arguments:
          type: string
          description: The arguments passed to the function
      description: The definition of the function that was called
    RunStepDeltaStepDetailsToolCallsCodeObject:
      title: Code interpreter tool call
      required:
      - index
      - type
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObjectCodeInterpreter'
          x-ballerina-name: codeInterpreter
        index:
          type: integer
          description: The index of the tool call in the tool calls array
        id:
          type: string
          description: The ID of the tool call
        type:
          type: string
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call
          enum:
          - code_interpreter
      description: Details of the Code Interpreter tool call the run step was involved
        in
    FunctionObject:
      required:
      - name
      type: object
      properties:
        name:
          type: string
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64"
        description:
          type: string
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function"
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
    CreateChatCompletionStreamResponseLogprobs:
      required:
      - content
      type: object
      properties:
        content:
          type: array
          description: A list of message content tokens with log probability information
          nullable: true
          items:
            $ref: '#/components/schemas/ChatCompletionTokenLogprob'
      description: Log probability information for the choice
      nullable: true
    CreateAssistantRequestToolResources:
      type: object
      properties:
        code_interpreter:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesCodeInterpreter'
          x-ballerina-name: codeInterpreter
        file_search:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResourcesFileSearch'
          x-ballerina-name: fileSearch
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
      nullable: true
    CreateAssistantRequest:
      required:
      - model
      type: object
      properties:
        top_p:
          maximum: 1
          minimum: 0
          type: number
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both
          nullable: true
          example: 1
          default: 1
          x-ballerina-name: topP
        instructions:
          maxLength: 256000
          type: string
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters
          nullable: true
        tool_resources:
          allOf:
          - $ref: '#/components/schemas/CreateAssistantRequestToolResources'
          x-ballerina-name: toolResources
        metadata:
          type: object
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
          nullable: true
          x-oaiTypeLabel: map
        response_format:
          allOf:
          - $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
          x-ballerina-name: responseFormat
        name:
          maxLength: 256
          type: string
          description: |
            The name of the assistant. The maximum length is 256 characters
          nullable: true
        temperature:
          maximum: 2
          minimum: 0
          type: number
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
          nullable: true
          example: 1
          default: 1
        description:
          maxLength: 512
          type: string
          description: |
            The description of the assistant. The maximum length is 512 characters
          nullable: true
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
          example: gpt-4-turbo
          anyOf:
          - type: string
          - type: string
            enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4o-mini
            - gpt-4o-mini-2024-07-18
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
          x-oaiTypeLabel: string
        tools:
          maxItems: 128
          type: array
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
          items:
            $ref: '#/components/schemas/CreateAssistantRequestTools'
          default: []
      additionalProperties: false
    DeleteVectorStoreResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - vector_store.deleted
    DeleteAssistantResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - assistant.deleted
    CreateAssistantRequestToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    ThreadStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/ThreadObject'
        event:
          type: string
          enum:
          - thread.created
      description: "Occurs when a new [thread](/docs/api-reference/threads/object)\
        \ is created"
      x-oaiMeta:
        dataDescription: "`data` is a [thread](/docs/api-reference/threads/object)"
    RunStepDetailsToolCallsFileSearchObject:
      title: File search tool call
      required:
      - file_search
      - id
      - type
      type: object
      properties:
        file_search:
          type: object
          description: "For now, this is always going to be an empty object"
          x-oaiTypeLabel: map
          x-ballerina-name: fileSearch
        id:
          type: string
          description: The ID of the tool call object
        type:
          type: string
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call
          enum:
          - file_search
    UploadPart:
      title: UploadPart
      required:
      - created_at
      - id
      - object
      - upload_id
      type: object
      properties:
        upload_id:
          type: string
          description: The ID of the Upload object that this Part was added to
          x-ballerina-name: uploadId
        created_at:
          type: integer
          description: The Unix timestamp (in seconds) for when the Part was created
          x-ballerina-name: createdAt
        id:
          type: string
          description: "The upload Part unique identifier, which can be referenced\
            \ in API endpoints"
        object:
          type: string
          description: "The object type, which is always `upload.part`"
          enum:
          - upload.part
      description: |
        The upload Part represents a chunk of bytes we can add to an Upload object
      x-oaiMeta:
        name: The upload part object
        example: |
          {
              "id": "part_def456",
              "object": "upload.part",
              "created_at": 1719186911,
              "upload_id": "upload_abc123"
          }
    RunStreamEventRunStreamEventRunStreamEventRunStreamEventOneOf1234:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/RunObject'
        event:
          type: string
          enum:
          - thread.run.requires_action
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `requires_action` status"
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    CreateChatCompletionResponse:
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      properties:
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion
            was created
        usage:
          $ref: '#/components/schemas/CompletionUsage'
        model:
          type: string
          description: The model used for the chat completion
        service_tier:
          type: string
          description: The service tier used for processing the request. This field
            is only included if the `service_tier` parameter is specified in the request
          nullable: true
          example: scale
          enum:
          - scale
          - default
          x-ballerina-name: serviceTier
        id:
          type: string
          description: A unique identifier for the chat completion
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1
          items:
            $ref: '#/components/schemas/CreateChatCompletionResponseChoices'
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
          x-ballerina-name: systemFingerprint
        object:
          type: string
          description: "The object type, which is always `chat.completion`"
          enum:
          - chat.completion
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input"
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-4o-mini",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "\n\nHello there, how may I assist you today?",
              },
              "logprobs": null,
              "finish_reason": "stop"
            }],
            "usage": {
              "prompt_tokens": 9,
              "completion_tokens": 12,
              "total_tokens": 21
            }
          }
    Error:
      required:
      - code
      - message
      - param
      - type
      type: object
      properties:
        code:
          type: string
          nullable: true
        param:
          type: string
          nullable: true
        message:
          type: string
          nullable: false
        type:
          type: string
          nullable: false
    ChatCompletionRequestAssistantMessageFunctionCall:
      required:
      - arguments
      - name
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call
        arguments:
          type: string
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function"
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model"
      nullable: true
      deprecated: true
    ChatCompletionRequestToolMessage:
      title: Tool message
      required:
      - content
      - role
      - tool_call_id
      type: object
      properties:
        role:
          type: string
          description: "The role of the messages author, in this case `tool`"
          enum:
          - tool
        tool_call_id:
          type: string
          description: Tool call that this message is responding to
          x-ballerina-name: toolCallId
        content:
          type: string
          description: The contents of the tool message
    CreateTranslationResponseJson:
      required:
      - text
      type: object
      properties:
        text:
          type: string
    ChatCompletionRequestMessageContentPartImageImageUrl:
      required:
      - url
      type: object
      properties:
        detail:
          type: string
          description: "Specifies the detail level of the image. Learn more in the\
            \ [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding)"
          default: auto
          enum:
          - auto
          - low
          - high
        url:
          type: string
          description: Either a URL of the image or the base64 encoded image data
          format: uri
    CreateImageVariationRequest:
      required:
      - image
      type: object
      properties:
        image:
          type: string
          description: "The image to use as the basis for the variation(s). Must be\
            \ a valid PNG file, less than 4MB, and square"
          format: binary
        response_format:
          type: string
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated
          nullable: true
          example: url
          default: url
          enum:
          - url
          - b64_json
          x-ballerina-name: responseFormat
        size:
          type: string
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`"
          nullable: true
          example: 1024x1024
          default: 1024x1024
          enum:
          - 256x256
          - 512x512
          - 1024x1024
        model:
          description: The model to use for image generation. Only `dall-e-2` is supported
            at this time
          nullable: true
          example: dall-e-2
          anyOf:
          - type: string
          - type: string
            enum:
            - dall-e-2
          default: dall-e-2
          x-oaiTypeLabel: string
        user:
          type: string
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
          example: user-1234
        "n":
          maximum: 10
          minimum: 1
          type: integer
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported"
          nullable: true
          example: 1
          default: 1
    MessageStreamEventOneOf1:
      required:
      - data
      - event
      type: object
      properties:
        data:
          $ref: '#/components/schemas/MessageObject'
        event:
          type: string
          enum:
          - thread.message.created
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ created"
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    ChatCompletionResponseMessage:
      required:
      - content
      - role
      type: object
      properties:
        role:
          type: string
          description: The role of the author of this message
          enum:
          - assistant
        function_call:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionResponseMessageFunctionCall'
          x-ballerina-name: functionCall
        tool_calls:
          allOf:
          - $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
          x-ballerina-name: toolCalls
        content:
          type: string
          description: The contents of the message
          nullable: true
      description: A chat completion message generated by the model
    DeleteThreadResponse:
      required:
      - deleted
      - id
      - object
      type: object
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
          enum:
          - thread.deleted
    BatchRequestOutput:
      type: object
      properties:
        response:
          $ref: '#/components/schemas/BatchRequestOutputResponse'
        custom_id:
          type: string
          description: A developer-provided per-request id that will be used to match
            outputs to inputs
          x-ballerina-name: customId
        id:
          type: string
        error:
          $ref: '#/components/schemas/BatchRequestOutputError'
      description: The per-line object of the batch output and error files
      x-oaiMeta:
        name: The request output object
        example: |
          {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-3.5-turbo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
    RunStepDetailsToolCallsCodeOutputLogsObject:
      title: Code Interpreter log output
      required:
      - logs
      - type
      type: object
      properties:
        type:
          type: string
          description: Always `logs`
          enum:
          - logs
        logs:
          type: string
          description: The text output from the Code Interpreter tool call
      description: Text output from the Code Interpreter tool call as part of a run
        step
    StaticChunkingStrategyResponseParam:
      title: Static Chunking Strategy
      required:
      - static
      - type
      type: object
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          type: string
          description: Always `static`
          enum:
          - static
      additionalProperties: false
    MessageObjectTools:
      oneOf:
      - $ref: '#/components/schemas/AssistantToolsCode'
      - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
      x-oaiExpandable: true
    RunStepDetailsMessageCreationObject:
      title: Message creation
      required:
      - message_creation
      - type
      type: object
      properties:
        message_creation:
          allOf:
          - $ref: '#/components/schemas/RunStepDetailsMessageCreationObjectMessageCreation'
          x-ballerina-name: messageCreation
        type:
          type: string
          description: Always `message_creation`
          enum:
          - message_creation
      description: Details of the message creation by the run step
    ThreadObjectToolResourcesCodeInterpreter:
      type: object
      properties:
        file_ids:
          maxItems: 20
          type: array
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
          items:
            type: string
          default: []
          x-ballerina-name: fileIds
    MessageContentImageFileObjectImageFile:
      required:
      - file_id
      type: object
      properties:
        file_id:
          type: string
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content"
          x-ballerina-name: fileId
        detail:
          type: string
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`"
          default: auto
          enum:
          - auto
          - low
          - high
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer
x-oaiMeta:
  navigationGroups:
  - id: endpoints
    title: Endpoints
  - id: assistants
    title: Assistants
  - id: legacy
    title: Legacy
  groups:
  - id: audio
    title: Audio
    description: |
      Learn how to turn audio into text or text into audio.

      Related guide: [Speech to text](/docs/guides/speech-to-text)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createSpeech
      path: createSpeech
    - type: endpoint
      key: createTranscription
      path: createTranscription
    - type: endpoint
      key: createTranslation
      path: createTranslation
    - type: object
      key: CreateTranscriptionResponseJson
      path: json-object
    - type: object
      key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
  - id: chat
    title: Chat
    description: |
      Given a list of messages comprising a conversation, the model will return a response.

      Related guide: [Chat Completions](/docs/guides/text-generation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createChatCompletion
      path: create
    - type: object
      key: CreateChatCompletionResponse
      path: object
    - type: object
      key: CreateChatCompletionStreamResponse
      path: streaming
  - id: embeddings
    title: Embeddings
    description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.

      Related guide: [Embeddings](/docs/guides/embeddings)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEmbedding
      path: create
    - type: object
      key: Embedding
      path: object
  - id: fine-tuning
    title: Fine-tuning
    description: |
      Manage fine-tuning jobs to tailor a model to your specific training data.

      Related guide: [Fine-tune models](/docs/guides/fine-tuning)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFineTuningJob
      path: create
    - type: endpoint
      key: listPaginatedFineTuningJobs
      path: list
    - type: endpoint
      key: listFineTuningEvents
      path: list-events
    - type: endpoint
      key: listFineTuningJobCheckpoints
      path: list-checkpoints
    - type: endpoint
      key: retrieveFineTuningJob
      path: retrieve
    - type: endpoint
      key: cancelFineTuningJob
      path: cancel
    - type: object
      key: FinetuneChatRequestInput
      path: chat-input
    - type: object
      key: FinetuneCompletionRequestInput
      path: completions-input
    - type: object
      key: FineTuningJob
      path: object
    - type: object
      key: FineTuningJobEvent
      path: event-object
    - type: object
      key: FineTuningJobCheckpoint
      path: checkpoint-object
  - id: batch
    title: Batch
    description: |
      Create large batches of API requests for asynchronous processing. The Batch API returns completions within 24 hours for a 50% discount.

      Related guide: [Batch](/docs/guides/batch)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createBatch
      path: create
    - type: endpoint
      key: retrieveBatch
      path: retrieve
    - type: endpoint
      key: cancelBatch
      path: cancel
    - type: endpoint
      key: listBatches
      path: list
    - type: object
      key: Batch
      path: object
    - type: object
      key: BatchRequestInput
      path: request-input
    - type: object
      key: BatchRequestOutput
      path: request-output
  - id: files
    title: Files
    description: |
      Files are used to upload documents that can be used with features like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch API](/docs/guides/batch).
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createFile
      path: create
    - type: endpoint
      key: listFiles
      path: list
    - type: endpoint
      key: retrieveFile
      path: retrieve
    - type: endpoint
      key: deleteFile
      path: delete
    - type: endpoint
      key: downloadFile
      path: retrieve-contents
    - type: object
      key: OpenAIFile
      path: object
  - id: uploads
    title: Uploads
    description: |
      Allows you to upload large files in multiple parts.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createUpload
      path: create
    - type: endpoint
      key: addUploadPart
      path: add-part
    - type: endpoint
      key: completeUpload
      path: complete
    - type: endpoint
      key: cancelUpload
      path: cancel
    - type: object
      key: Upload
      path: object
    - type: object
      key: UploadPart
      path: part-object
  - id: images
    title: Images
    description: |
      Given a prompt and/or an input image, the model will generate a new image.

      Related guide: [Image generation](/docs/guides/images)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createImage
      path: create
    - type: endpoint
      key: createImageEdit
      path: createEdit
    - type: endpoint
      key: createImageVariation
      path: createVariation
    - type: object
      key: Image
      path: object
  - id: models
    title: Models
    description: |
      List and describe the various models available in the API. You can refer to the [Models](/docs/models) documentation to understand what models are available and the differences between them.
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: listModels
      path: list
    - type: endpoint
      key: retrieveModel
      path: retrieve
    - type: endpoint
      key: deleteModel
      path: delete
    - type: object
      key: Model
      path: object
  - id: moderations
    title: Moderations
    description: |
      Given some input text, outputs if the model classifies it as potentially harmful across several categories.

      Related guide: [Moderations](/docs/guides/moderation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createModeration
      path: create
    - type: object
      key: CreateModerationResponse
      path: object
  - id: assistants
    title: Assistants
    beta: true
    description: |
      Build assistants that can call models and use tools to perform tasks.

      [Get started with the Assistants API](/docs/assistants)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createAssistant
      path: createAssistant
    - type: endpoint
      key: listAssistants
      path: listAssistants
    - type: endpoint
      key: getAssistant
      path: getAssistant
    - type: endpoint
      key: modifyAssistant
      path: modifyAssistant
    - type: endpoint
      key: deleteAssistant
      path: deleteAssistant
    - type: object
      key: AssistantObject
      path: object
  - id: threads
    title: Threads
    beta: true
    description: |
      Create threads that assistants can interact with.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createThread
      path: createThread
    - type: endpoint
      key: getThread
      path: getThread
    - type: endpoint
      key: modifyThread
      path: modifyThread
    - type: endpoint
      key: deleteThread
      path: deleteThread
    - type: object
      key: ThreadObject
      path: object
  - id: messages
    title: Messages
    beta: true
    description: |
      Create messages within threads

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createMessage
      path: createMessage
    - type: endpoint
      key: listMessages
      path: listMessages
    - type: endpoint
      key: getMessage
      path: getMessage
    - type: endpoint
      key: modifyMessage
      path: modifyMessage
    - type: endpoint
      key: deleteMessage
      path: deleteMessage
    - type: object
      key: MessageObject
      path: object
  - id: runs
    title: Runs
    beta: true
    description: |
      Represents an execution run on a thread.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createRun
      path: createRun
    - type: endpoint
      key: createThreadAndRun
      path: createThreadAndRun
    - type: endpoint
      key: listRuns
      path: listRuns
    - type: endpoint
      key: getRun
      path: getRun
    - type: endpoint
      key: modifyRun
      path: modifyRun
    - type: endpoint
      key: submitToolOuputsToRun
      path: submitToolOutputs
    - type: endpoint
      key: cancelRun
      path: cancelRun
    - type: object
      key: RunObject
      path: object
  - id: run-steps
    title: Run Steps
    beta: true
    description: |
      Represents the steps (model and tool calls) taken during the run.

      Related guide: [Assistants](/docs/assistants/overview)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: listRunSteps
      path: listRunSteps
    - type: endpoint
      key: getRunStep
      path: getRunStep
    - type: object
      key: RunStepObject
      path: step-object
  - id: vector-stores
    title: Vector Stores
    beta: true
    description: |
      Vector stores are used to store files for use by the `file_search` tool.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStore
      path: create
    - type: endpoint
      key: listVectorStores
      path: list
    - type: endpoint
      key: getVectorStore
      path: retrieve
    - type: endpoint
      key: modifyVectorStore
      path: modify
    - type: endpoint
      key: deleteVectorStore
      path: delete
    - type: object
      key: VectorStoreObject
      path: object
  - id: vector-stores-files
    title: Vector Store Files
    beta: true
    description: |
      Vector store files represent files inside a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStoreFile
      path: createFile
    - type: endpoint
      key: listVectorStoreFiles
      path: listFiles
    - type: endpoint
      key: getVectorStoreFile
      path: getFile
    - type: endpoint
      key: deleteVectorStoreFile
      path: deleteFile
    - type: object
      key: VectorStoreFileObject
      path: file-object
  - id: vector-stores-file-batches
    title: Vector Store File Batches
    beta: true
    description: |
      Vector store file batches represent operations to add multiple files to a vector store.

      Related guide: [File Search](/docs/assistants/tools/file-search)
    navigationGroup: assistants
    sections:
    - type: endpoint
      key: createVectorStoreFileBatch
      path: createBatch
    - type: endpoint
      key: getVectorStoreFileBatch
      path: getBatch
    - type: endpoint
      key: cancelVectorStoreFileBatch
      path: cancelBatch
    - type: endpoint
      key: listFilesInVectorStoreBatch
      path: listBatchFiles
    - type: object
      key: VectorStoreFileBatchObject
      path: batch-object
  - id: assistants-streaming
    title: Streaming
    beta: true
    description: |
      Stream the result of executing a Run or resuming a Run after submitting tool outputs.

      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),
      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)
      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events) stream.

      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference the
      [Assistants API quickstart](/docs/assistants/overview) to learn more.
    navigationGroup: assistants
    sections:
    - type: object
      key: MessageDeltaObject
      path: message-delta-object
    - type: object
      key: RunStepDeltaObject
      path: run-step-delta-object
    - type: object
      key: AssistantStreamEvent
      path: events
  - id: completions
    title: Completions
    legacy: true
    navigationGroup: legacy
    description: |
      Given a prompt, the model will return one or more predicted completions along with the probabilities of alternative tokens at each position. Most developer should use our [Chat Completions API](/docs/guides/text-generation/text-generation-models) to leverage our best and newest models.
    sections:
    - type: endpoint
      key: createCompletion
      path: create
    - type: object
      key: CreateCompletionResponse
      path: object
